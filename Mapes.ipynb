{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8ZNNXRwxJ9L",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kg--Mw_xeuKa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find header.dxf (GDAL_DATA is not defined)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from itertools import combinations\n",
    "import sys\n",
    "\n",
    "import math\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union, nearest_points\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium\n",
    "from folium import GeoJson, LayerControl\n",
    "from branca.colormap import linear\n",
    "import branca.colormap as cm\n",
    "\n",
    "import igraph as ig\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_flooded_roads(edges, nodes, flood_zones, name):\n",
    "    output_path = cut_roads_files[name]\n",
    "    graphml_path = safe_roads_files[name]\n",
    "\n",
    "    #if os.path.exists(output_path) and layer in fiona.listlayers(output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Loading {name} from {output_path}\")\n",
    "        G_safe = ox.load_graphml(graphml_path)\n",
    "        edges = gpd.read_file(output_path, layer=name)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Tagging and saving {name} to {output_path}\")\n",
    "\n",
    "        bounds = edges.total_bounds\n",
    "        flood_subset = flood_zones.cx[bounds[0]:bounds[2], bounds[1]:bounds[3]]\n",
    "        flood_geoms = flood_subset.geometry\n",
    "\n",
    "        edges = edges.copy()\n",
    "        edges[\"in_flood_zone\"] = edges.geometry.apply(lambda geom: flood_geoms.intersects(geom).any())\n",
    "\n",
    "        edges.to_file(output_path, layer=name, driver=\"GPKG\")\n",
    "\n",
    "    if os.path.exists(graphml_path):\n",
    "        print(\"Pruned graph already exists\")\n",
    "    else:    \n",
    "        safe_edges = edges[~edges[\"in_flood_zone\"]].copy()\n",
    "        print(\"Rebuilding pruned graph...\")\n",
    "        G_safe = ox.graph_from_gdfs(nodes, safe_edges)\n",
    "        ox.save_graphml(G_safe, filepath=graphml_path)\n",
    "        print(f\"Saved pruned graph to {graphml_path}\")\n",
    "\n",
    "    return edges, G_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_flood_zone(return_crs, name, clip_geom):\n",
    "    output_path = zone_output_files[name]\n",
    "    input_path = zone_input_files[name]\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Loading {name} from {output_path}\")\n",
    "        clipped = gpd.read_file(output_path, layer=name).to_crs(return_crs)\n",
    "    else:\n",
    "        print(f\"Clipping and saving {name} from {output_path}\" )\n",
    "        flood = gpd.read_file(input_path).to_crs(return_crs)\n",
    "        clipped = gpd.clip(flood, clip_geom)\n",
    "        clipped.to_file(output_path, layer=name, driver=\"GPKG\")\n",
    "\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_geojson_safe(gdf):\n",
    "    gdf = gdf.copy()\n",
    "    dt_cols = gdf.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]']).columns\n",
    "    gdf[dt_cols] = gdf[dt_cols].astype(str)\n",
    "    for col in gdf.columns:\n",
    "        if col != \"geometry\" and not pd.api.types.is_scalar(gdf[col].iloc[0]):\n",
    "            gdf.drop(columns=[col], inplace=True)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flood_zone_layer(name, m):\n",
    "    gdf=flood_zones_var[name]\n",
    "    color=color_palette[name]\n",
    "    if gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    gdf_serializable = make_geojson_safe(gdf)\n",
    "\n",
    "    style_function = lambda x: {\n",
    "        'fillColor': color,\n",
    "        'color': color,\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.4\n",
    "    }\n",
    "\n",
    "    geojson = folium.GeoJson(\n",
    "        data=gdf_serializable,\n",
    "        name=f\"Flood {name}\",\n",
    "        style_function=style_function,\n",
    "        show=False\n",
    "    )\n",
    "    geojson.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_roads_layer(name, m, flood):\n",
    "    if flood:\n",
    "        roads = flood_edges_var[name].copy()\n",
    "        roads = roads[roads[\"in_flood_zone\"] == flood]\n",
    "    else:\n",
    "        roads = edges.copy()\n",
    "\n",
    "    roads = roads.to_crs(epsg=4326)\n",
    "    roads = make_geojson_safe(roads)\n",
    "\n",
    "    style_function = lambda x: {\n",
    "        'color': color_palette[name],\n",
    "        'weight': 2,\n",
    "        'opacity': 0.6\n",
    "    }\n",
    "\n",
    "    if flood == True:\n",
    "        geojson = folium.GeoJson(\n",
    "            roads,\n",
    "            name=f\"Flooded Roads {name}\",\n",
    "            style_function=style_function,\n",
    "            show=False\n",
    "        )\n",
    "    else:\n",
    "            geojson = folium.GeoJson(\n",
    "            roads,\n",
    "            name=f\"All roads\",\n",
    "            style_function=style_function,\n",
    "            show=False\n",
    "        )\n",
    "    \n",
    "    geojson.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_roads_layer_risk(name, m, flood):\n",
    "    if flood:\n",
    "        roads = flood_edges_var[name].copy()\n",
    "        roads = roads[roads[\"in_flood_zone\"] == flood]\n",
    "    else:\n",
    "        roads = edges.copy()\n",
    "\n",
    "    roads = roads.to_crs(epsg=4326)\n",
    "    roads = make_geojson_safe(roads)\n",
    "\n",
    "    style_function = lambda x: {\n",
    "        'color': color_palette[name],\n",
    "        'weight': 2,\n",
    "        'opacity': 0.6\n",
    "    }\n",
    "\n",
    "    if flood == True:\n",
    "        geojson = folium.GeoJson(\n",
    "            roads,\n",
    "            name=f\"Flooded Roads {name}\",\n",
    "            style_function=style_function,\n",
    "            show=False\n",
    "        )\n",
    "    else:\n",
    "            geojson = folium.GeoJson(\n",
    "            roads,\n",
    "            name=f\"All roads\",\n",
    "            style_function=style_function,\n",
    "            show=False\n",
    "        )\n",
    "    \n",
    "    geojson.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_depth_range(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "\n",
    "    val = val.strip()\n",
    "\n",
    "    if val.startswith('Below'):\n",
    "        return float(val[5:].strip()) / 2\n",
    "\n",
    "    if val.startswith('>'):\n",
    "        return float(val[1:].strip())  # You may want to cap it\n",
    "\n",
    "    if '-' in val:\n",
    "        parts = val.split('-')\n",
    "        try:\n",
    "            low = float(parts[0].strip())\n",
    "            high = float(parts[1].strip())\n",
    "            return (low + high) / 2\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_individual_risk_factor(T_P, T_NP):\n",
    "    if T_P == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 - (T_NP / T_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_risk_factor(T_P_dict, T_NP_dict):\n",
    "    keys = set(T_P_dict.keys()) & set(T_NP_dict.keys())\n",
    "    R = 0\n",
    "    for k in keys:\n",
    "        T_P_time = T_P_dict[k][1]\n",
    "        T_NP_time = T_NP_dict[k][1]\n",
    "        R += compute_individual_risk_factor(T_P_time, T_NP_time)\n",
    "    R /= len(keys) if keys else 1\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_risk_factor_2(T_P_dict, T_NP_dict): #when not computing paths\n",
    "    keys = set(T_P_dict.keys()) & set(T_NP_dict.keys())\n",
    "    R = 0\n",
    "    for k in keys:\n",
    "        T_P_time = T_P_dict[k]\n",
    "        T_NP_time = T_NP_dict[k][1]\n",
    "        R += compute_individual_risk_factor(T_P_time, T_NP_time)\n",
    "    R /= len(keys) if keys else 1\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_municipal_risk_factor(T_P_dict, T_NP_dict, municipality):\n",
    "    keys = {k for k in T_P_dict.keys() & T_NP_dict.keys() if municipality in k}\n",
    "    R = 0\n",
    "    for k in keys:\n",
    "        T_P_time = T_P_dict[k][1]\n",
    "        T_NP_time = T_NP_dict[k][1]\n",
    "        R += compute_individual_risk_factor(T_P_time, T_NP_time)\n",
    "    R /= len(keys) if keys else 1\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_depth_zones(name):\n",
    "    layer=\"depth_val\"\n",
    "    input_path = depth_input_files[name]\n",
    "    output_path=depth_output_files[name]\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Loading {layer} from {output_path}\")\n",
    "        depth=gpd.read_file(output_path, layer=layer)\n",
    "    else:\n",
    "        print(f\"Saving {layer} to {output_path}\")\n",
    "        depth = gpd.read_file(input_path)\n",
    "        depth[\"depth_val\"] = depth[\"value\"].apply(parse_depth_range)\n",
    "        depth.to_file(output_path, layer=layer, driver=\"GPKG\")\n",
    "        print(f\"Saved processed {layer} in {output_path}\")\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nx_to_igraph(G_nx, weight_attr='travel_time'):\n",
    "    node_list = list(G_nx.nodes())\n",
    "    node_to_index = {node: i for i, node in enumerate(node_list)}\n",
    "    index_to_node = {i: node for node, i in node_to_index.items()}\n",
    "\n",
    "    edge_weights = {}\n",
    "    for u, v, attr in G_nx.edges(data=True):\n",
    "        wt = attr.get(weight_attr)\n",
    "        if wt is None:\n",
    "            continue\n",
    "        u_idx, v_idx = node_to_index[u], node_to_index[v]\n",
    "        if (u_idx, v_idx) not in edge_weights or wt < edge_weights[(u_idx, v_idx)]:\n",
    "            edge_weights[(u_idx, v_idx)] = wt\n",
    "\n",
    "    is_directed = G_nx.is_directed()\n",
    "    G_ig = ig.Graph(directed=is_directed)\n",
    "    G_ig.add_vertices(len(node_list))\n",
    "    G_ig.add_edges(edge_weights.keys())\n",
    "    G_ig.es['weight'] = list(edge_weights.values())\n",
    "\n",
    "    return G_ig, node_to_index, index_to_node, edge_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_shortest_paths(G_ig, special_nodes, index_to_node, node_to_index, node_to_muni, compute_path, weight_attr='weight'):\n",
    "    result = {}\n",
    "    special_indices = [node_to_index[n] for n in special_nodes]\n",
    "    index_to_muni = {idx: node_to_muni[index_to_node[idx]] for idx in special_indices}\n",
    "\n",
    "    for src_idx in special_indices:\n",
    "        distances = G_ig.distances(source=src_idx, target=special_indices, weights=weight_attr)[0]\n",
    "        paths = None\n",
    "        if compute_path:\n",
    "            paths = G_ig.get_shortest_paths(src_idx, to=special_indices, weights=weight_attr, output='vpath')\n",
    "\n",
    "        for tgt_pos, tgt_idx in enumerate(special_indices):\n",
    "            if src_idx == tgt_idx:\n",
    "                continue\n",
    "\n",
    "            dist = distances[tgt_pos]\n",
    "            if math.isinf(dist):\n",
    "                result[f\"{index_to_muni[src_idx]}__{index_to_muni[tgt_idx]}\"] = ([], 0) if compute_path else 0\n",
    "                continue\n",
    "\n",
    "            if compute_path:\n",
    "                node_path = paths[tgt_pos]\n",
    "                path = [index_to_node[n] for n in node_path] if node_path else []\n",
    "                result[f\"{index_to_muni[src_idx]}__{index_to_muni[tgt_idx]}\"] = (path, dist)\n",
    "            else:\n",
    "                result[f\"{index_to_muni[src_idx]}__{index_to_muni[tgt_idx]}\"] = dist\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_shortest_paths_no_path(G_ig, special_nodes, index_to_node, node_to_index, node_to_muni, weight_attr='weight'):\n",
    "    result = {}\n",
    "\n",
    "    special_indices = [node_to_index[n] for n in special_nodes]\n",
    "    index_to_muni = {idx: node_to_muni[index_to_node[idx]] for idx in special_indices}\n",
    "\n",
    "    dist_matrix = G_ig.shortest_paths_dijkstra(\n",
    "        source=special_indices,\n",
    "        target=special_indices,\n",
    "        weights=weight_attr\n",
    "    )\n",
    "\n",
    "    for i, src_idx in enumerate(special_indices):\n",
    "        for j, tgt_idx in enumerate(special_indices):\n",
    "            if src_idx == tgt_idx:\n",
    "                continue\n",
    "\n",
    "            dist = dist_matrix[i][j]\n",
    "            key = f\"{index_to_muni[src_idx]}__{index_to_muni[tgt_idx]}\"\n",
    "            result[key] = 0 if math.isinf(dist) else dist\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_compute_shortest_paths(filename, G_nx, special_nodes, node_to_muni, save, compute_path):\n",
    "    G_ig, node_to_index, index_to_node, edge_weights = convert_nx_to_igraph(G_nx, weight_attr='travel_time')\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Deserialize: convert lists to tuples if compute_path is True\n",
    "        if compute_path:\n",
    "            result = {k: (v[0], v[1]) for k, v in data.items()}\n",
    "        else:\n",
    "            result = data  # just distances\n",
    "    else:\n",
    "        print(\"Computing shortest paths...\")\n",
    "        result = batch_shortest_paths(\n",
    "            G_ig,\n",
    "            special_nodes,\n",
    "            index_to_node,\n",
    "            node_to_index,\n",
    "            node_to_muni,\n",
    "            compute_path=compute_path\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            if compute_path:\n",
    "                # Convert tuples to lists for JSON compatibility\n",
    "                serializable_result = {k: [v[0], v[1]] for k, v in result.items()}\n",
    "            else:\n",
    "                # Values are just floats\n",
    "                serializable_result = result\n",
    "\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(serializable_result, f)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae_V4hjCAsN8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Street data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CPYUcbX01Hvy"
   },
   "outputs": [],
   "source": [
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "polygon_path = os.path.join(output_dir, \"study_area.geojson\")\n",
    "graph_path = os.path.join(output_dir, \"road_graph.graphml\")\n",
    "\n",
    "valencia_municipalities = [\"Alaquàs\", \"Albal\", \"Albalat de la Ribera\", \"Alberic\", \"Alborache\", \"Alcàsser\", \"l'Alcúdia\", \"Aldaia\", \"Alfafar\", \"Alfarb\", \"Algemesí\", \n",
    "                           \"Alginet\", \"Almussafes\", \"Alzira\", \"Aras de los Olmos\", \"Barxeta\", \"Benagéber\", \"Benaguasil\", \"Benetússer\", \"Benicull de Xúquer\", \n",
    "                           \"Benifaió\", \"Benimuslem\", \"Beniparrell\", \"Benimodo\", \"Bétera\", \"Bugarra\", \"Buñol\", \"Calles\", \"Camporrobles\", \"Carcaixent\", \"Carlet\", \n",
    "                           \"Casinos\", \"Castelló de la Ribera\", \"Catadau\", \"Catarroja\", \"Caudete de las Fuentes\", \"Chelva\",\"Chera\", \"Cheste\", \"Chiva\", \"Chulilla\", \n",
    "                           \"Corbera\", \"Cullera\", \"Dos Aguas\", \"Favara\", \"Fortaleny\", \"Fuenterrobles\", \"Gavarda\", \"Gestalgar\", \"Godelleta\", \"Guadassuar\", \"l'Ènova\", \n",
    "                           \"Llaurí\", \"Llombai\", \"Llíria\", \"Llocnou de la Corona\", \"Loriguilla\", \"Losa del Obispo\", \"Macastre\", \"Manises\", \"Manuel\", \"Massalavés\", \n",
    "                           \"Massanassa\", \"Millares\", \"Mislata\", \"Montroi\", \"Montserrat\", \"Paiporta\", \"Paterna\", \"Pedralba\", \"Picanya\", \"Picassent\", \n",
    "                           \"Polinyà de Xúquer\", \"La Pobla Llarga\", \"Quart de Poblet\", \"Rafelguaraf\", \"Real\", \"Requena\", \"Riba-roja de Túria\", \"Riola\", \n",
    "                           \"Sant Joanet\", \"Sedaví\", \"Senyera\", \"Siete Aguas\", \"Silla\", \"Sinarcas\", \"Sollana\", \"Sot de Chera\", \"Sueca\", \"Tavernes de la Valldigna\", \n",
    "                           \"Titaguas\", \"Torrent\", \"Tous\", \"Tuéjar\", \"Turís\", \"Utiel\", \"València\", \"Vilamarxant\", \"Villar del Arzobispo\", \"Xeraco\", \"Xirivella\", \n",
    "                           \"Yátova\"]\n",
    "\n",
    "urban_center={\n",
    "    \"Alaquàs\": (39.457119, -0.460822), \n",
    "    \"Albal\": (39.397347, -0.413243), \n",
    "    \"Albalat de la Ribera\": (39.201133, -0.386659),\n",
    "    \"Alberic\": (39.116783, -0.517571),\n",
    "    \"Alborache\": (39.391716, -0.771191),\n",
    "    \"Alcàsser\": (39.369810, -0.445176),\n",
    "    \"l'Alcúdia\": (39.194077, -0.507206),\n",
    "    \"Aldaia\": (39.464957, -0.460764),\n",
    "    \"Alfafar\": (39.422773, -0.390834), \n",
    "    \"Alfarb\": (39.276849, -0.560529),\n",
    "    \"Algemesí\": (39.188743, -0.436927),\n",
    "    \"Alginet\": (39.261819, -0.469791),\n",
    "    \"Almussafes\": (39.292656, -0.413260),\n",
    "    \"Alzira\": (39.152038, -0.441074),\n",
    "    \"Aras de los Olmos\": (39.924534, -1.132748),\n",
    "    \"Barxeta\": (39.022865, -0.416099),\n",
    "    \"Benagéber\": (39.707324, -1.100825),\n",
    "    \"Benaguasil\": (39.593635, -0.585004),\n",
    "    \"Benetússer\": (39.423801, -0.397785),\n",
    "    \"Benicull de Xúquer\": (39.185063, -0.382524), \n",
    "    \"Benifaió\": (39.285003, -0.426889),\n",
    "    \"Benimuslem\": (39.131337, -0.492750),\n",
    "    \"Beniparrell\": (39.382235, -0.412277), \n",
    "    \"Benimodo\": (39.213015, -0.528357), \n",
    "    \"Bétera\": (39.591643, -0.462355),\n",
    "    \"Bugarra\": (39.608415, -0.775958), \n",
    "    \"Buñol\": (39.418217, -0.790672), \n",
    "    \"Calles\": (39.725371, -0.973952), \n",
    "    \"Camporrobles\": (39.647167, -1.399476), \n",
    "    \"Carcaixent\": (39.122600, -0.450718), \n",
    "    \"Carlet\": (39.225881, -0.519809),\n",
    "    \"Casinos\": (39.701574, -0.709655),\n",
    "    \"Castelló de la ribera\": (39.079664, -0.514174),\n",
    "    #\"Castielfabib\": (40.131018, -1.303874),\n",
    "    \"Catadau\": (39.275363, -0.569740), \n",
    "    \"Catarroja\": (39.403048, -0.404021),\n",
    "    \"Caudete de las Fuentes\": (39.558958, -1.278492),\n",
    "    \"Chelva\": (39.747097, -0.997692),\n",
    "    \"Chera\": (39.593442, -0.973241), \n",
    "    \"Cheste\": (39.494909, -0.684261), \n",
    "    \"Chiva\": (39.471469, -0.717100), \n",
    "    \"Chulilla\": (39.656217, -0.891905), \n",
    "    \"Corbera\": (39.158264, -0.355378), \n",
    "    \"Cullera\": (39.165250, -0.253612),\n",
    "    \"Dos Aguas\": (39.288825, -0.800238), \n",
    "    \"Favara\": (39.127275, -0.291808), \n",
    "    \"Fortaleny\": (39.183833, -0.313715), \n",
    "    \"Fuenterrobles\": (39.584682, -1.364031),\n",
    "    \"Gavarda\": (39.090082, -0.545045),\n",
    "    \"Gestalgar\": (39.604207, -0.834346), \n",
    "    \"Godelleta\": (39.422040, -0.686434), \n",
    "    \"Guadassuar\": (39.185852, -0.478023),\n",
    "    \"l'Ènova\": (39.045134, -0.480790), \n",
    "    \"Llaurí\": (39.147102, -0.330235), \n",
    "    \"Llombai\": (39.282414, -0.572366), \n",
    "    \"Llíria\": (39.624719, -0.595006), \n",
    "    \"Llocnou de la Corona\": (39.420446, -0.382216), \n",
    "    \"Loriguilla\": (39.489698, -0.571964),\n",
    "    \"Losa del Obispo\": (39.695444, -0.871960),\n",
    "    \"Macastre\": (39.381938, -0.785287),\n",
    "    \"Manises\": (39.493345, -0.457466), \n",
    "    \"Manuel\": (39.052760, -0.494055),\n",
    "    \"Massalavés\": (39.140675, -0.521159),\n",
    "    \"Massanassa\": (39.411460, -0.397986), \n",
    "    \"Millares\": (39.238985, -0.773203), \n",
    "    \"Mislata\": (39.475218, -0.417833), \n",
    "    \"Montroi\": (39.341742, -0.613689), \n",
    "    \"Montserrat\": (39.358012, -0.603212), \n",
    "    \"Paiporta\": (39.429588, -0.417467),\n",
    "    \"Paterna\": (39.500663, -0.439682), \n",
    "    \"Pedralba\": (39.604864, -0.726535), \n",
    "    \"Picanya\": (39.435146, -0.433490), \n",
    "    \"Picassent\": (39.362746, -0.458078), \n",
    "    \"Polinyà de Xúquer\": (39.196150, -0.369461), \n",
    "    \"La Pobla Llarga\": (39.085916, -0.475557),\n",
    "    \"Quart de Poblet\": (39.483003, -0.442288), \n",
    "    \"Rafelguaraf\": (39.050797, -0.455126), \n",
    "    \"Real\": (39.335088, -0.609125), \n",
    "    \"Requena\": (39.487037, -1.098087), \n",
    "    \"Riba-roja de Túria\": (39.546926, -0.566891), \n",
    "    \"Riola\": (39.195261, -0.334682),\n",
    "    \"Sant Joanet\": (39.072333, -0.486829),\n",
    "    \"Sedaví\": (39.425005, -0.385783),\n",
    "    \"Senyera\": (39.063613, -0.510467), \n",
    "    \"Siete Aguas\": (39.471633, -0.915872), \n",
    "    \"Silla\": (39.362679, -0.412147), \n",
    "    \"Sinarcas\": (39.733258, -1.229035), \n",
    "    \"Sollana\": (39.278009, -0.381457), \n",
    "    \"Sot de Chera\": (39.620816, -0.909344), \n",
    "    \"Sueca\": (39.202640, -0.310637),\n",
    "    \"Tavernes de la Valldigna\": (39.071834, -0.267740),\n",
    "    \"Titaguas\": (39.865889, -1.080723),\n",
    "    \"Torrent\": (39.436931, -0.465889), \n",
    "    \"Tous\": (39.138561, -0.586636), \n",
    "    \"Tuéjar\": (39.763485, -1.039679),\n",
    "    \"Turís\": (39.389834, -0.711107), \n",
    "    \"Utiel\": (39.566851, -1.206009), \n",
    "    \"València\": (39.469844, -0.376852), \n",
    "    \"Vilamarxant\": (39.567855, -0.622488),\n",
    "    \"Villar del Arzobispo\": (39.730829, -0.825240),\n",
    "    \"Xeraco\": (39.033395, -0.215323),\n",
    "    \"Xirivella\": (39.463360, -0.428399),\n",
    "    \"Yátova\":(39.385085, -0.808117),\n",
    "    \"Mira\": (39.720949, -1.439225)\n",
    "} \n",
    "\n",
    "print(len(valencia_municipalities))\n",
    "print(len(urban_center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 07:48:42,416 [INFO] Downloading polygons for municipalities...\n",
      "2025-07-11 07:48:46,531 [INFO] Created 103 records\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(polygon_path):\n",
    "    logging.info(\"Loading saved study area polygon...\")\n",
    "    study_area = gpd.read_file(polygon_path)\n",
    "else:\n",
    "    logging.info(\"Downloading polygons for municipalities...\")\n",
    "    polygons = []\n",
    "\n",
    "    for municipality in valencia_municipalities:\n",
    "        try:\n",
    "            place_name = f\"{municipality}, Valencia, Spain\"\n",
    "            gdf = ox.geocode_to_gdf(place_name)\n",
    "\n",
    "            if gdf.crs != \"EPSG:4326\":\n",
    "                gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "            polygons.append(gdf)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error retrieving {municipality}: {e}\", exc_info=True)\n",
    "\n",
    "    # Add Mira from Cuenca (just in case)\n",
    "    try:\n",
    "        gdf = ox.geocode_to_gdf(\"Mira, Cuenca, Spain\")\n",
    "        if gdf.crs != \"EPSG:4326\":\n",
    "            gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "        polygons.append(gdf)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error retrieving Mira: {e}\", exc_info=True)\n",
    "\n",
    "    study_area = gpd.GeoDataFrame(pd.concat(polygons, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    study_area = study_area[study_area.geometry.notnull()]\n",
    "    study_area.to_file(polygon_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 07:48:53,445 [INFO] Polygon geometry union complete.\n"
     ]
    }
   ],
   "source": [
    "study_area = study_area[study_area.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "polygon = unary_union(study_area.geometry)\n",
    "logging.info(\"Polygon geometry union complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 07:49:15,987 [INFO] Loading saved road network graph...\n",
      "2025-07-11 07:50:16,060 [INFO] Converted graph to GeoDataFrames.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(graph_path):\n",
    "    logging.info(\"Loading saved road network graph...\")\n",
    "    G = ox.load_graphml(graph_path)\n",
    "    \n",
    "else:\n",
    "    logging.info(\"Downloading road network...\")\n",
    "\n",
    "    G = ox.graph_from_polygon(\n",
    "        polygon,\n",
    "        network_type=\"drive\",\n",
    "        simplify=True,\n",
    "        retain_all=False,\n",
    "        truncate_by_edge=True\n",
    "    )\n",
    "\n",
    "    logging.info(\"Calculating travel times...\")\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        if \"length\" in data:\n",
    "            speed = None\n",
    "\n",
    "            if \"maxspeed\" in data:\n",
    "                maxspeed = data[\"maxspeed\"]\n",
    "                if isinstance(maxspeed, list):\n",
    "                    speed = maxspeed[0]\n",
    "                else:\n",
    "                    speed = maxspeed\n",
    "\n",
    "                try:\n",
    "                    speed = float(str(maxspeed).split()[0])  # Handle \"50 km/h\" etc.\n",
    "                except ValueError:\n",
    "                    speed = None  # Fallback to highway-based speed below\n",
    "\n",
    "            if speed is None:\n",
    "                highway = data.get(\"highway\", \"\")\n",
    "                if isinstance(highway, list):\n",
    "                    highway = highway[0]\n",
    "                speed = {\n",
    "                    \"motorway\": 120,\n",
    "                    \"motorway_link\": 60,\n",
    "                    \"trunk\": 100,\n",
    "                    \"primary\": 80,\n",
    "                    \"secondary\": 60,\n",
    "                    \"tertiary\": 50,\n",
    "                    \"residential\": 30,\n",
    "                    \"living_street\": 10,\n",
    "                    \"unclassified\": 40,\n",
    "                    \"service\": 20\n",
    "                }.get(highway, 50)  # fallback 50 km/h\n",
    "\n",
    "            surface = data.get(\"surface\", \"\").lower()\n",
    "            surface_speed_factor = {\n",
    "                \"paved\": 1.0,\n",
    "                \"asphalt\": 1.0,\n",
    "                \"concrete\": 1.0,\n",
    "                \"cobblestone\": 0.8,\n",
    "                \"gravel\": 0.7,\n",
    "                \"dirt\": 0.6,\n",
    "                \"ground\": 0.6,\n",
    "                \"sand\": 0.5,\n",
    "                \"unpaved\": 0.7,\n",
    "                \"compacted\": 0.85,\n",
    "                \"fine_gravel\": 0.9\n",
    "            }\n",
    "            for key, factor in surface_speed_factor.items():\n",
    "                if key in surface:\n",
    "                    speed *= factor\n",
    "                    break \n",
    "\n",
    "            speed_mps = speed * 1000 / 3600\n",
    "            data[\"travel_time\"] = data[\"length\"] / speed_mps\n",
    "            data[\"travel_time\"] += 5 # Turn penalty approximation\n",
    "\n",
    "    ox.save_graphml(G, filepath=graph_path)\n",
    "    logging.info(\"Graph saved.\")\n",
    "\n",
    "nodes, edges = ox.graph_to_gdfs(G)\n",
    "logging.info(\"Converted graph to GeoDataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 07:51:41,575 [INFO] Updated graph saved to: processed_files\\road_graph.graphml\n"
     ]
    }
   ],
   "source": [
    "node_coords = np.array([(geom.y, geom.x) for geom in nodes.geometry])\n",
    "kdtree = cKDTree(node_coords)\n",
    "\n",
    "if 'municipality' not in nodes.columns:\n",
    "    nodes['municipality'] = \"\"\n",
    "\n",
    "for name, (lat, lon) in urban_center.items():\n",
    "    try:\n",
    "        # Query closest node index\n",
    "        _, idx = kdtree.query([lat, lon], k=1)\n",
    "        nearest_node_idx = nodes.index[idx]\n",
    "        nodes.at[nearest_node_idx, 'municipality'] = name\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error assigning municipality {name}: {e}\")\n",
    "\n",
    "\n",
    "for node_id, row in nodes.iterrows():\n",
    "    G.nodes[node_id]['municipality'] = row['municipality']\n",
    "\n",
    "ox.save_graphml(G, graph_path)\n",
    "logging.info(f\"Updated graph saved to: {graph_path}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 07:51:41,624 [INFO] 'municipality' field already exists in nodes.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "if 'municipality' not in nodes.columns:\n",
    "    logging.info(\"Adding 'municipality' field to nodes...\")\n",
    "\n",
    "    nodes['municipality'] = \"\"\n",
    "\n",
    "    node_coords = np.array([(geom.y, geom.x) for geom in nodes.geometry])\n",
    "    kdtree = cKDTree(node_coords)\n",
    "\n",
    "    for _, row in study_area.iterrows():\n",
    "        name = row.get(\"name\") or row.get(\"display_name\") or \"unknown\"\n",
    "        geom = row.geometry\n",
    "\n",
    "        if not geom or not geom.is_valid or name == \"Favara\":\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            muni_graph = ox.graph_from_polygon(geom, network_type='drive', simplify=True)\n",
    "            center_node = ox.distance.nearest_nodes(muni_graph, X=geom.centroid.x, Y=geom.centroid.y)\n",
    "            center_point = Point((muni_graph.nodes[center_node]['x'], muni_graph.nodes[center_node]['y']))\n",
    "            _, idx = kdtree.query([center_point.y, center_point.x], k=1)\n",
    "            nearest_node_idx = nodes.index[idx]\n",
    "            nodes.at[nearest_node_idx, 'municipality'] = name\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not process {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    for node_id, row in nodes.iterrows():\n",
    "        G.nodes[node_id]['municipality'] = row['municipality']\n",
    "\n",
    "    graph_path = os.path.join(output_dir, \"road_graph.graphml\")\n",
    "    ox.save_graphml(G, graph_path)\n",
    "    logging.info(f\"Updated graph saved to: {graph_path}\")\n",
    "\n",
    "else:\n",
    "    logging.info(\"'municipality' field already exists in nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail=False\n",
    "if rail:\n",
    "    graph_path_rail = os.path.join(output_dir, \"study_area_rail.graphml\")\n",
    "    if os.path.exists(graph_path_rail):\n",
    "        print(\"Loading saved rail network graph...\")\n",
    "        G_rail = ox.load_graphml(graph_path_rail)\n",
    "    else:\n",
    "        print(\"Downloading rail network graph...\")\n",
    "        rail_filter = '[\"railway\"~\"rail|light_rail|subway|tram\"]'\n",
    "        G_rail = ox.graph_from_polygon(polygon, custom_filter=rail_filter, network_type=\"all\")\n",
    "        ox.save_graphml(G_rail, filepath=graph_path_rail)\n",
    "\n",
    "    nodes_rail, edges_rail = ox.graph_to_gdfs(G_rail)\n",
    "    del G_rail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"source_files\"\n",
    "output_dir = \"processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_input_files = {\n",
    "    \"10 yr\": f\"{input_dir}/laminaspb-q10/Q10_2Ciclo_PB_20241121.shp\",\n",
    "    \"100 yr\": f\"{input_dir}/laminaspb-q100/Q100_2Ciclo_PB_20241121_ETRS89.shp\",\n",
    "    \"500 yr\": f\"{input_dir}/laminaspb-q500/Q500_2Ciclo_PB_20241121_ETRS89.shp\",\n",
    "    \"DANA_31_10_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_PRODUCT_v1/EMSR773_AOI01_DEL_PRODUCT_observedEventA_v1.shp\",\n",
    "    \"DANA_03_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT01_v1/EMSR773_AOI01_DEL_MONIT01_observedEventA_v1.shp\",\n",
    "    \"DANA_05_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT02_v1/EMSR773_AOI01_DEL_MONIT02_observedEventA_v1.shp\",\n",
    "    \"DANA_06_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT03_v1/EMSR773_AOI01_DEL_MONIT03_observedEventA_v1.shp\",\n",
    "    \"DANA_08_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT04_v1/EMSR773_AOI01_DEL_MONIT04_observedEventA_v1.shp\"\n",
    "}\n",
    "\n",
    "depth_input_files = {\n",
    "    \"DANA_31_10_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_PRODUCT_v1/EMSR773_AOI01_DEL_PRODUCT_floodDepthA_v1.shp\",\n",
    "    \"DANA_03_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT01_v1/EMSR773_AOI01_DEL_MONIT01_floodDepthA_v1.shp\",\n",
    "    \"DANA_05_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT02_v1/EMSR773_AOI01_DEL_MONIT02_floodDepthA_v1.shp\",\n",
    "    \"DANA_06_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT03_v1/EMSR773_AOI01_DEL_MONIT03_floodDepthA_v1.shp\",\n",
    "    \"DANA_08_11_2024\": f\"{input_dir}/EMSR773_AOI01_DEL_MONIT04_v1/EMSR773_AOI01_DEL_MONIT04_floodDepthA_v1.shp\"\n",
    "}\n",
    "\n",
    "zone_output_files = {\n",
    "    \"10 yr\": f\"{output_dir}/zone_flood_risk_10.gpkg\",\n",
    "    \"100 yr\": f\"{output_dir}/zone_flood_risk_100.gpkg\",\n",
    "    \"500 yr\": f\"{output_dir}/zone_flood_risk_500.gpkg\",\n",
    "    \"DANA_31_10_2024\": f\"{output_dir}/zone_DANA_31_10_2024.gpkg\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/zone_DANA_03_11_2024.gpkg\",\n",
    "    \"DANA_05_11_2024\": f\"{output_dir}/zone_DANA_05_11_2024.gpkg\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/zone_DANA_06_11_2024.gpkg\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/zone_DANA_08_11_2024.gpkg\"\n",
    "}\n",
    "\n",
    "depth_output_files = {\n",
    "    \"DANA_31_10_2024\": f\"{output_dir}/depth_DANA_31_10_2024.gpkg\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/depth_DANA_03_11_2024.gpkg\",\n",
    "    \"DANA_05_11_2024\": f\"{output_dir}/depth_DANA_05_11_2024.gpkg\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/depth_DANA_06_11_2024.gpkg\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/depth_DANA_08_11_2024.gpkg\"\n",
    "}\n",
    "\n",
    "cut_roads_files = {\n",
    "    \"10 yr\": f\"{output_dir}/cut_roads_flood_risk_10.graphml\",\n",
    "    \"100 yr\": f\"{output_dir}/cut_roads_flood_risk_100.graphml\",\n",
    "    \"500 yr\": f\"{output_dir}/cut_roads_flood_risk_500.graphml\",\n",
    "    \"DANA_31_10_2024\": f\"{output_dir}/cut_roads_DANA_31_10_2024.graphml\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/cut_roads_DANA_03_11_2024.graphml\",\n",
    "    \"DANA_05_11_2024\": f\"{output_dir}/cut_roads_DANA_05_11_2024.graphml\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/cut_roads_DANA_06_11_2024.graphml\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/cut_roads_DANA_08_11_2024.graphml\"\n",
    "}\n",
    "\n",
    "safe_roads_files = {\n",
    "    \"10 yr\": f\"{output_dir}/safe_roads_flood_risk_10.graphml\",\n",
    "    \"100 yr\": f\"{output_dir}/safe_roads_flood_risk_100.graphml\",\n",
    "    \"500 yr\": f\"{output_dir}/safe_roads_flood_risk_500.graphml\",\n",
    "    \"DANA_31_10_2024\": f\"{output_dir}/safe_roads_DANA_31_10_2024.graphml\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/safe_roads_DANA_03_11_2024.graphml\",\n",
    "    \"DANA_05_11_2024\": f\"{output_dir}/safe_roads_DANA_05_11_2024.graphml\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/safe_roads_DANA_06_11_2024.graphml\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/safe_roads_DANA_08_11_2024.graphml\"\n",
    "}\n",
    "\n",
    "shortest_path_files = {\n",
    "    \"Normal Conditions\": f\"{output_dir}/shorthest_paths_NP.json\", \n",
    "    \"10 yr\": f\"{output_dir}/shorthest_paths_10.json\",\n",
    "    \"100 yr\": f\"{output_dir}/shorthest_paths_100.json\",\n",
    "    \"500 yr\": f\"{output_dir}/shorthest_paths_500.json\",\n",
    "    \"DANA_31_10_2024\": f\"{output_dir}/shorthest_paths_DANA_31_10_2024.json\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/shorthest_paths_DANA_03_11_2024.json\",\n",
    "    \"DANA_05_11_2024\": f\"{output_dir}/shorthest_paths_DANA_05_11_2024.json\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/shorthest_paths_DANA_06_11_2024.json\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/shorthest_paths_DANA_08_11_2024.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "im671dntApI-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Flood zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names=[\"10 yr\",\"100 yr\",\"500 yr\",\"DANA_31_10_2024\",\"DANA_03_11_2024\",\"DANA_05_11_2024\",\"DANA_06_11_2024\",\"DANA_08_11_2024\"]\n",
    "#layer_names=[\"DANA_31_10_2024\"]\n",
    "flood_zones_var = {}\n",
    "flood_edges_var = {}\n",
    "flood_graph_var = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10 yr from processed_files/zone_flood_risk_10.gpkg\n",
      "Loading 10 yr from processed_files/cut_roads_flood_risk_10.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_flood_risk_10.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading 100 yr from processed_files/zone_flood_risk_100.gpkg\n",
      "Loading 100 yr from processed_files/cut_roads_flood_risk_100.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_flood_risk_100.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading 500 yr from processed_files/zone_flood_risk_500.gpkg\n",
      "Loading 500 yr from processed_files/cut_roads_flood_risk_500.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_flood_risk_500.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading DANA_31_10_2024 from processed_files/zone_DANA_31_10_2024.gpkg\n",
      "Loading DANA_31_10_2024 from processed_files/cut_roads_DANA_31_10_2024.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_DANA_31_10_2024.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading DANA_03_11_2024 from processed_files/zone_DANA_03_11_2024.gpkg\n",
      "Loading DANA_03_11_2024 from processed_files/cut_roads_DANA_03_11_2024.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_DANA_03_11_2024.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading DANA_05_11_2024 from processed_files/zone_DANA_05_11_2024.gpkg\n",
      "Loading DANA_05_11_2024 from processed_files/cut_roads_DANA_05_11_2024.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_DANA_05_11_2024.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading DANA_06_11_2024 from processed_files/zone_DANA_06_11_2024.gpkg\n",
      "Loading DANA_06_11_2024 from processed_files/cut_roads_DANA_06_11_2024.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_DANA_06_11_2024.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n",
      "Loading DANA_08_11_2024 from processed_files/zone_DANA_08_11_2024.gpkg\n",
      "Loading DANA_08_11_2024 from processed_files/cut_roads_DANA_08_11_2024.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\oxenv\\lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: File processed_files/cut_roads_DANA_08_11_2024.graphml has GPKG application_id, but non conformant file extension\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned graph already exists\n"
     ]
    }
   ],
   "source": [
    "for name in layer_names: \n",
    "    result = clip_flood_zone(edges.crs, name, polygon)\n",
    "    flood_zones_var[name] = result\n",
    "    result_1, result_2 = tag_flooded_roads(edges, nodes, result, name)\n",
    "    flood_edges_var[name] = result_1\n",
    "    flood_graph_var[name] = result_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [\"DANA_31_10_2024\",\"DANA_03_11_2024\",\"DANA_05_11_2024\",\"DANA_06_11_2024\",\"DANA_08_11_2024\"]\n",
    "depth_zones = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading depth_val from processed_files/depth_DANA_31_10_2024.gpkg\n",
      "Loading depth_val from processed_files/depth_DANA_03_11_2024.gpkg\n",
      "Loading depth_val from processed_files/depth_DANA_05_11_2024.gpkg\n",
      "Loading depth_val from processed_files/depth_DANA_06_11_2024.gpkg\n",
      "Loading depth_val from processed_files/depth_DANA_08_11_2024.gpkg\n"
     ]
    }
   ],
   "source": [
    "for name in layer_names: \n",
    "    depth = flood_depth_zones(name)\n",
    "    depth_zones[name]=depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navegability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = shortest_path_files[\"Normal Conditions\"]\n",
    "\n",
    "special_nodes = [n for n, attr in G.nodes(data=True) if attr.get('municipality')]\n",
    "node_to_muni = {n: attr.get('municipality', '') for n, attr in G.nodes(data=True)}\n",
    "\n",
    "T_NP_dictionary = load_or_compute_shortest_paths(filename, G, special_nodes, node_to_muni,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 yr 7 weakly connected components\n",
      "Component 1 municipalities: {'Tous', 'Benetússer', 'Picanya', 'Sot de Chera', 'Camporrobles', 'Silla', 'Torrent', 'Albalat de la Ribera', 'Almussafes', 'Alfafar', 'Carlet', 'Alborache', 'Villar del Arzobispo', 'Llíria', 'Albal', 'Alginet', 'Yátova', 'Caudete de las Fuentes', 'València', 'Riola', 'Chera', 'Catadau', 'Catarroja', 'Real', 'Losa del Obispo', 'Bétera', 'Utiel', 'Fortaleny', 'Casinos', 'Cheste', 'Llaurí', 'Sollana', 'Macastre', 'Beniparrell', 'Riba-roja de Túria', 'Corbera', 'Pedralba', 'Chiva', 'Llombai', 'Vilamarxant', 'Alaquàs', 'Paterna', 'Sedaví', 'Fuenterrobles', 'Benifaió', 'Benaguasil', 'Turís', 'Massanassa', 'Massalavés', 'Favara', 'Tavernes de la Valldigna', 'Sueca', 'Gavarda', 'Godelleta', 'Gestalgar', 'Llocnou de la Corona', 'Chulilla', 'Buñol', 'Benicull de Xúquer', 'Cullera', 'Guadassuar', 'Paiporta', 'Sinarcas', 'Bugarra', 'Benimuslem', 'Aldaia', 'Manises', 'Loriguilla', 'Alberic', 'Benimodo', \"l'Alcúdia\", 'Picassent', 'Siete Aguas', 'Alcàsser', 'Requena', 'Xirivella', 'Polinyà de Xúquer', 'Alzira', 'Montroi', 'Quart de Poblet', 'Benagéber', 'Mislata', 'Alfarb', 'Montserrat', 'Algemesí'}\n",
      "Component 2 municipalities: {'Barxeta', 'Rafelguaraf', 'Manuel', 'Senyera', 'Castelló de la ribera', 'La Pobla Llarga', 'Sant Joanet', \"l'Ènova\", 'Carcaixent'}\n",
      "Component 3 municipalities: {'Xeraco'}\n",
      "Component 4 municipalities: {'Dos Aguas'}\n",
      "Component 5 municipalities: {'Millares'}\n",
      "Component 6 municipalities: {'Calles', 'Chelva', 'Titaguas', 'Tuéjar', 'Aras de los Olmos'}\n",
      "Component 7 municipalities: {'Mira'}\n",
      "100 yr 30 weakly connected components\n",
      "Component 1 municipalities: {'Alberic', 'Tous', 'Massalavés', 'Picanya', 'Benimodo', 'Silla', 'Torrent', 'Gavarda', 'Godelleta', 'Almussafes', 'Picassent', 'Siete Aguas', 'Alcàsser', 'Buñol', 'Carlet', 'Alborache', 'Macastre', 'Albal', 'Chiva', 'Alginet', 'Yátova', 'Llombai', 'Montroi', 'Benifaió', 'Alfarb', 'Catadau', 'Montserrat', 'Turís', 'Catarroja'}\n",
      "Component 2 municipalities: {'Algemesí'}\n",
      "Component 3 municipalities: {'Guadassuar'}\n",
      "Component 4 municipalities: {\"l'Alcúdia\"}\n",
      "Component 5 municipalities: {'Corbera', 'Tavernes de la Valldigna', 'Favara', 'Llaurí'}\n",
      "Component 6 municipalities: {'Manuel', 'Senyera', 'Castelló de la ribera', 'La Pobla Llarga', 'Sant Joanet', \"l'Ènova\"}\n",
      "Component 7 municipalities: {'Xeraco'}\n",
      "Component 8 municipalities: {'Cullera', 'Sueca'}\n",
      "Component 9 municipalities: {'Sollana'}\n",
      "Component 10 municipalities: {'Albalat de la Ribera'}\n",
      "Component 11 municipalities: {'Riola'}\n",
      "Component 12 municipalities: {'Barxeta'}\n",
      "Component 13 municipalities: {'Polinyà de Xúquer'}\n",
      "Component 14 municipalities: {'Alzira'}\n",
      "Component 15 municipalities: {'Fortaleny'}\n",
      "Component 16 municipalities: {'Benicull de Xúquer'}\n",
      "Component 17 municipalities: {'Benimuslem'}\n",
      "Component 18 municipalities: {'Rafelguaraf'}\n",
      "Component 19 municipalities: {'Real'}\n",
      "Component 20 municipalities: {'Dos Aguas'}\n",
      "Component 21 municipalities: {'Benetússer', 'Massanassa', 'Losa del Obispo', 'Bétera', 'Sot de Chera', 'Gestalgar', 'Llocnou de la Corona', 'Chulilla', 'Casinos', 'Cheste', 'Alfafar', 'Villar del Arzobispo', 'Llíria', 'Paiporta', 'Xirivella', 'Riba-roja de Túria', 'Bugarra', 'Pedralba', 'Vilamarxant', 'Alaquàs', 'València', 'Quart de Poblet', 'Paterna', 'Sedaví', 'Manises', 'Loriguilla', 'Mislata', 'Benaguasil'}\n",
      "Component 22 municipalities: {'Fuenterrobles', 'Caudete de las Fuentes', 'Camporrobles'}\n",
      "Component 23 municipalities: {'Millares'}\n",
      "Component 24 municipalities: {'Sinarcas', 'Benagéber', 'Chera', 'Utiel', 'Requena'}\n",
      "Component 25 municipalities: {'Titaguas', 'Aras de los Olmos', 'Chelva', 'Tuéjar'}\n",
      "Component 26 municipalities: {'Calles'}\n",
      "Component 27 municipalities: {'Mira'}\n",
      "Component 28 municipalities: {'Carcaixent'}\n",
      "Component 29 municipalities: {'Aldaia'}\n",
      "Component 30 municipalities: {'Beniparrell'}\n",
      "500 yr 45 weakly connected components\n",
      "Component 1 municipalities: {'Alberic', 'Tous', 'Massalavés', 'Benimodo', 'Carlet', 'Alfarb', 'Catadau', 'Llombai', 'Gavarda'}\n",
      "Component 2 municipalities: {'Algemesí'}\n",
      "Component 3 municipalities: {'Godelleta', 'Macastre', 'Albal', 'Picassent', 'Siete Aguas', 'Picanya', 'Alcàsser', 'Chiva', 'Buñol', 'Benifaió', 'Alborache', 'Yátova', 'Silla', 'Montserrat', 'Turís', 'Torrent', 'Montroi'}\n",
      "Component 4 municipalities: {\"l'Alcúdia\"}\n",
      "Component 5 municipalities: {'Corbera', 'Favara', 'Llaurí'}\n",
      "Component 6 municipalities: {'Manuel', 'Senyera', 'Castelló de la ribera', 'La Pobla Llarga', 'Sant Joanet', \"l'Ènova\"}\n",
      "Component 7 municipalities: {'Xeraco'}\n",
      "Component 8 municipalities: {'Cullera', 'Sueca'}\n",
      "Component 9 municipalities: {'Tavernes de la Valldigna'}\n",
      "Component 10 municipalities: {'Sollana'}\n",
      "Component 11 municipalities: {'Albalat de la Ribera'}\n",
      "Component 12 municipalities: {'Riola'}\n",
      "Component 13 municipalities: {'Barxeta'}\n",
      "Component 14 municipalities: {'Polinyà de Xúquer'}\n",
      "Component 15 municipalities: {'Guadassuar'}\n",
      "Component 16 municipalities: {'Alginet'}\n",
      "Component 17 municipalities: {'Fortaleny'}\n",
      "Component 18 municipalities: {'Benicull de Xúquer'}\n",
      "Component 19 municipalities: {'Benimuslem'}\n",
      "Component 20 municipalities: {'Alzira'}\n",
      "Component 21 municipalities: {'Real'}\n",
      "Component 22 municipalities: {'Dos Aguas'}\n",
      "Component 23 municipalities: {'Mislata', 'València'}\n",
      "Component 24 municipalities: {'Paterna', 'Bétera'}\n",
      "Component 25 municipalities: {'Quart de Poblet', 'Gestalgar', 'Chulilla', 'Riba-roja de Túria', 'Casinos', 'Bugarra', 'Cheste', 'Losa del Obispo', 'Loriguilla', 'Sot de Chera', 'Manises', 'Benaguasil', 'Vilamarxant', 'Llíria'}\n",
      "Component 26 municipalities: {'Benetússer', 'Llocnou de la Corona', 'Sedaví', 'Alfafar', 'Alaquàs', 'Paiporta'}\n",
      "Component 27 municipalities: {'Fuenterrobles', 'Caudete de las Fuentes', 'Camporrobles'}\n",
      "Component 28 municipalities: {'Millares'}\n",
      "Component 29 municipalities: {'Chera', 'Requena', 'Benagéber'}\n",
      "Component 30 municipalities: {'Pedralba'}\n",
      "Component 31 municipalities: {'Aras de los Olmos', 'Tuéjar', 'Titaguas'}\n",
      "Component 32 municipalities: {'Chelva'}\n",
      "Component 33 municipalities: {'Villar del Arzobispo'}\n",
      "Component 34 municipalities: {'Sinarcas'}\n",
      "Component 35 municipalities: {'Mira'}\n",
      "Component 36 municipalities: {'Xirivella'}\n",
      "Component 37 municipalities: {'Rafelguaraf'}\n",
      "Component 38 municipalities: {'Catarroja'}\n",
      "Component 39 municipalities: {'Massanassa'}\n",
      "Component 40 municipalities: {'Carcaixent'}\n",
      "Component 41 municipalities: {'Calles'}\n",
      "Component 42 municipalities: {'Utiel'}\n",
      "Component 43 municipalities: {'Almussafes'}\n",
      "Component 44 municipalities: {'Beniparrell'}\n",
      "Component 45 municipalities: {'Aldaia'}\n",
      "DANA_31_10_2024 27 weakly connected components\n",
      "Component 1 municipalities: {'Gavarda'}\n",
      "Component 2 municipalities: {'Tous', 'Benetússer', 'Massanassa', 'Massalavés', 'Losa del Obispo', 'Benimodo', 'Bétera', 'Sot de Chera', 'Tuéjar', 'Utiel', 'Silla', 'Aras de los Olmos', 'Torrent', 'Godelleta', 'Gestalgar', 'Chulilla', 'Almussafes', 'Chelva', 'Picassent', 'Casinos', 'Cheste', 'Siete Aguas', 'Alfafar', 'Alcàsser', 'Buñol', 'Carlet', 'Alborache', 'Sollana', 'Requena', 'Villar del Arzobispo', 'Llíria', 'Calles', 'Macastre', 'Riba-roja de Túria', 'Albal', 'Titaguas', 'Bugarra', 'Pedralba', 'Chiva', 'Dos Aguas', 'Alginet', 'Yátova', 'Llombai', 'Vilamarxant', 'Caudete de las Fuentes', 'Alaquàs', 'València', 'Montroi', 'Quart de Poblet', 'Paterna', 'Sedaví', 'Benagéber', 'Aldaia', 'Chera', 'Manises', 'Loriguilla', 'Fuenterrobles', 'Benifaió', 'Mislata', 'Alfarb', 'Benaguasil', 'Catadau', 'Montserrat', 'Turís', 'Catarroja', 'Real', 'Millares'}\n",
      "Component 3 municipalities: {'Algemesí'}\n",
      "Component 4 municipalities: {'Corbera', 'Manuel', 'Xeraco', 'Favara', 'Carcaixent', 'Llaurí', 'Cullera', 'Tavernes de la Valldigna', \"l'Ènova\", 'Barxeta', 'Alzira'}\n",
      "Component 5 municipalities: {'Sueca'}\n",
      "Component 6 municipalities: {'Albalat de la Ribera'}\n",
      "Component 7 municipalities: {'Riola'}\n",
      "Component 8 municipalities: {'Polinyà de Xúquer'}\n",
      "Component 9 municipalities: {'Guadassuar'}\n",
      "Component 10 municipalities: {'Fortaleny'}\n",
      "Component 11 municipalities: {'Senyera'}\n",
      "Component 12 municipalities: {'Camporrobles'}\n",
      "Component 13 municipalities: {'Sinarcas'}\n",
      "Component 14 municipalities: {'Mira'}\n",
      "Component 15 municipalities: {'Xirivella'}\n",
      "Component 16 municipalities: {'Picanya'}\n",
      "Component 17 municipalities: {'Benicull de Xúquer'}\n",
      "Component 18 municipalities: {\"l'Alcúdia\"}\n",
      "Component 19 municipalities: {'Llocnou de la Corona'}\n",
      "Component 20 municipalities: {'Paiporta'}\n",
      "Component 21 municipalities: {'Rafelguaraf'}\n",
      "Component 22 municipalities: {'Castelló de la ribera'}\n",
      "Component 23 municipalities: {'La Pobla Llarga'}\n",
      "Component 24 municipalities: {'Sant Joanet'}\n",
      "Component 25 municipalities: {'Alberic'}\n",
      "Component 26 municipalities: {'Beniparrell'}\n",
      "Component 27 municipalities: {'Benimuslem'}\n",
      "DANA_03_11_2024 1 weakly connected components\n",
      "Component 1 municipalities: {'Tous', 'Benetússer', 'Picanya', 'Sot de Chera', 'Tuéjar', 'Camporrobles', 'Silla', 'Torrent', 'Albalat de la Ribera', 'Almussafes', 'Alfafar', 'Carlet', 'Alborache', 'La Pobla Llarga', 'Villar del Arzobispo', 'Llíria', 'Manuel', 'Albal', 'Castelló de la ribera', 'Alginet', 'Yátova', 'Caudete de las Fuentes', 'València', 'Riola', 'Chera', 'Catadau', 'Catarroja', 'Real', 'Losa del Obispo', 'Bétera', 'Utiel', 'Fortaleny', 'Chelva', 'Casinos', 'Cheste', 'Llaurí', 'Sollana', \"l'Ènova\", 'Barxeta', 'Calles', 'Macastre', 'Beniparrell', 'Riba-roja de Túria', 'Titaguas', 'Corbera', 'Pedralba', 'Chiva', 'Llombai', 'Vilamarxant', 'Alaquàs', 'Paterna', 'Sedaví', 'Xeraco', 'Fuenterrobles', 'Benifaió', 'Benaguasil', 'Turís', 'Massanassa', 'Massalavés', 'Favara', 'Tavernes de la Valldigna', 'Sueca', 'Gavarda', 'Godelleta', 'Gestalgar', 'Llocnou de la Corona', 'Rafelguaraf', 'Chulilla', 'Buñol', 'Benicull de Xúquer', 'Cullera', 'Guadassuar', 'Paiporta', 'Sinarcas', 'Bugarra', 'Benimuslem', 'Aldaia', 'Manises', 'Loriguilla', 'Alberic', 'Benimodo', 'Aras de los Olmos', 'Carcaixent', \"l'Alcúdia\", 'Picassent', 'Siete Aguas', 'Senyera', 'Alcàsser', 'Requena', 'Xirivella', 'Polinyà de Xúquer', 'Dos Aguas', 'Alzira', 'Mira', 'Montroi', 'Quart de Poblet', 'Benagéber', 'Mislata', 'Alfarb', 'Montserrat', 'Sant Joanet', 'Algemesí', 'Millares'}\n",
      "DANA_05_11_2024 1 weakly connected components\n",
      "Component 1 municipalities: {'Tous', 'Benetússer', 'Picanya', 'Sot de Chera', 'Tuéjar', 'Camporrobles', 'Silla', 'Torrent', 'Albalat de la Ribera', 'Almussafes', 'Alfafar', 'Carlet', 'Alborache', 'La Pobla Llarga', 'Villar del Arzobispo', 'Llíria', 'Manuel', 'Albal', 'Castelló de la ribera', 'Alginet', 'Yátova', 'Caudete de las Fuentes', 'València', 'Riola', 'Chera', 'Catadau', 'Catarroja', 'Real', 'Losa del Obispo', 'Bétera', 'Utiel', 'Fortaleny', 'Chelva', 'Casinos', 'Cheste', 'Llaurí', 'Sollana', \"l'Ènova\", 'Barxeta', 'Calles', 'Macastre', 'Beniparrell', 'Riba-roja de Túria', 'Titaguas', 'Corbera', 'Pedralba', 'Chiva', 'Llombai', 'Vilamarxant', 'Alaquàs', 'Paterna', 'Sedaví', 'Xeraco', 'Fuenterrobles', 'Benifaió', 'Benaguasil', 'Turís', 'Massanassa', 'Massalavés', 'Favara', 'Tavernes de la Valldigna', 'Sueca', 'Gavarda', 'Godelleta', 'Gestalgar', 'Llocnou de la Corona', 'Rafelguaraf', 'Chulilla', 'Buñol', 'Benicull de Xúquer', 'Cullera', 'Guadassuar', 'Paiporta', 'Sinarcas', 'Bugarra', 'Benimuslem', 'Aldaia', 'Manises', 'Loriguilla', 'Alberic', 'Benimodo', 'Aras de los Olmos', 'Carcaixent', \"l'Alcúdia\", 'Picassent', 'Siete Aguas', 'Senyera', 'Alcàsser', 'Requena', 'Xirivella', 'Polinyà de Xúquer', 'Dos Aguas', 'Alzira', 'Mira', 'Montroi', 'Quart de Poblet', 'Benagéber', 'Mislata', 'Alfarb', 'Montserrat', 'Sant Joanet', 'Algemesí', 'Millares'}\n",
      "DANA_06_11_2024 1 weakly connected components\n",
      "Component 1 municipalities: {'Tous', 'Benetússer', 'Picanya', 'Sot de Chera', 'Tuéjar', 'Camporrobles', 'Silla', 'Torrent', 'Albalat de la Ribera', 'Almussafes', 'Alfafar', 'Carlet', 'Alborache', 'La Pobla Llarga', 'Villar del Arzobispo', 'Llíria', 'Manuel', 'Albal', 'Castelló de la ribera', 'Alginet', 'Yátova', 'Caudete de las Fuentes', 'València', 'Riola', 'Chera', 'Catadau', 'Catarroja', 'Real', 'Losa del Obispo', 'Bétera', 'Utiel', 'Fortaleny', 'Chelva', 'Casinos', 'Cheste', 'Llaurí', 'Sollana', \"l'Ènova\", 'Barxeta', 'Calles', 'Macastre', 'Beniparrell', 'Riba-roja de Túria', 'Titaguas', 'Corbera', 'Pedralba', 'Chiva', 'Llombai', 'Vilamarxant', 'Alaquàs', 'Paterna', 'Sedaví', 'Xeraco', 'Fuenterrobles', 'Benifaió', 'Benaguasil', 'Turís', 'Massanassa', 'Massalavés', 'Favara', 'Tavernes de la Valldigna', 'Sueca', 'Gavarda', 'Godelleta', 'Gestalgar', 'Llocnou de la Corona', 'Rafelguaraf', 'Chulilla', 'Buñol', 'Benicull de Xúquer', 'Cullera', 'Guadassuar', 'Paiporta', 'Sinarcas', 'Bugarra', 'Benimuslem', 'Aldaia', 'Manises', 'Loriguilla', 'Alberic', 'Benimodo', 'Aras de los Olmos', 'Carcaixent', \"l'Alcúdia\", 'Picassent', 'Siete Aguas', 'Senyera', 'Alcàsser', 'Requena', 'Xirivella', 'Polinyà de Xúquer', 'Dos Aguas', 'Alzira', 'Mira', 'Montroi', 'Quart de Poblet', 'Benagéber', 'Mislata', 'Alfarb', 'Montserrat', 'Sant Joanet', 'Algemesí', 'Millares'}\n",
      "DANA_08_11_2024 1 weakly connected components\n",
      "Component 1 municipalities: {'Tous', 'Benetússer', 'Picanya', 'Sot de Chera', 'Tuéjar', 'Camporrobles', 'Silla', 'Torrent', 'Albalat de la Ribera', 'Almussafes', 'Alfafar', 'Carlet', 'Alborache', 'La Pobla Llarga', 'Villar del Arzobispo', 'Llíria', 'Manuel', 'Albal', 'Castelló de la ribera', 'Alginet', 'Yátova', 'Caudete de las Fuentes', 'València', 'Riola', 'Chera', 'Catadau', 'Catarroja', 'Real', 'Losa del Obispo', 'Bétera', 'Utiel', 'Fortaleny', 'Chelva', 'Casinos', 'Cheste', 'Llaurí', 'Sollana', \"l'Ènova\", 'Barxeta', 'Calles', 'Macastre', 'Beniparrell', 'Riba-roja de Túria', 'Titaguas', 'Corbera', 'Pedralba', 'Chiva', 'Llombai', 'Vilamarxant', 'Alaquàs', 'Paterna', 'Sedaví', 'Xeraco', 'Fuenterrobles', 'Benifaió', 'Benaguasil', 'Turís', 'Massanassa', 'Massalavés', 'Favara', 'Tavernes de la Valldigna', 'Sueca', 'Gavarda', 'Godelleta', 'Gestalgar', 'Llocnou de la Corona', 'Rafelguaraf', 'Chulilla', 'Buñol', 'Benicull de Xúquer', 'Cullera', 'Guadassuar', 'Paiporta', 'Sinarcas', 'Bugarra', 'Benimuslem', 'Aldaia', 'Manises', 'Loriguilla', 'Alberic', 'Benimodo', 'Aras de los Olmos', 'Carcaixent', \"l'Alcúdia\", 'Picassent', 'Siete Aguas', 'Senyera', 'Alcàsser', 'Requena', 'Xirivella', 'Polinyà de Xúquer', 'Dos Aguas', 'Alzira', 'Mira', 'Montroi', 'Quart de Poblet', 'Benagéber', 'Mislata', 'Alfarb', 'Montserrat', 'Sant Joanet', 'Algemesí', 'Millares'}\n"
     ]
    }
   ],
   "source": [
    "for name, graph in flood_graph_var.items():\n",
    "    components = list(nx.weakly_connected_components(graph))\n",
    "    \n",
    "    multi_muni_count = sum(\n",
    "        1 for component in components\n",
    "        if len({graph.nodes[node][\"municipality\"] for node in component if graph.nodes[node][\"municipality\"] != \"\"}) > 0\n",
    "    )\n",
    "\n",
    "    print(f\"{name} {multi_muni_count} weakly connected components\")\n",
    "\n",
    "    if multi_muni_count > 0:\n",
    "        j = 0\n",
    "        for i, component in enumerate(components):\n",
    "            municipalities = {\n",
    "                graph.nodes[node][\"municipality\"]\n",
    "                for node in component\n",
    "                if graph.nodes[node][\"municipality\"] != \"\"\n",
    "            }\n",
    "            if len(municipalities) > 0:\n",
    "                j += 1\n",
    "                print(f\"Component {j} municipalities: {municipalities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names=[\"10 yr\",\"100 yr\",\"500 yr\",\"DANA_31_10_2024\",\"DANA_03_11_2024\",\"DANA_05_11_2024\",\"DANA_06_11_2024\",\"DANA_08_11_2024\"]\n",
    "#layer_names=[\"DANA_31_10_2024\"]\n",
    "T_P_dictionaries = {}\n",
    "R={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.00% (8/8)"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(layer_names):\n",
    "    T_P_dictionaries[name] = load_or_compute_shortest_paths(shortest_path_files[name], flood_graph_var[name], special_nodes, node_to_muni,True,True)\n",
    "    R[name] = compute_risk_factor(T_P_dictionaries[name], T_NP_dictionary)\n",
    "    \n",
    "    percent_complete = (i + 1) / len(layer_names) * 100\n",
    "    print(f\"\\rProgress: {percent_complete:.2f}% ({i + 1}/{len(layer_names)})\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_edges = set()\n",
    "\n",
    "for path, _ in T_NP_dictionary.values():\n",
    "    for u, v in zip(path, path[1:]):\n",
    "        used_edges.add((u, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "G_ig, node_to_index, index_to_node, edge_weights = convert_nx_to_igraph(G, weight_attr='travel_time')  # <<< CHANGED (save edge_weights)\n",
    "special_indices = [node_to_index[n] for n in special_nodes]\n",
    "\n",
    "base_risk = 0\n",
    "edge_risks = []\n",
    "i=0\n",
    "total = len(used_edges)\n",
    "#total = 100\n",
    "\n",
    "for u, v in list(used_edges)[:total]:\n",
    "    i+=1\n",
    "    u_idx, v_idx = node_to_index[u], node_to_index[v]\n",
    "    eid = G_ig.get_eid(u_idx, v_idx, directed=True, error=False)  # <<< NEW (get edge id in igraph)\n",
    "    if eid == -1:\n",
    "        continue\n",
    "\n",
    "    # Remove edge in-place\n",
    "    G_ig.delete_edges(eid)  # <<< NEW (remove edge without copying)\n",
    "\n",
    "    # Compute shortest paths after removal (without full paths)\n",
    "    T_P_dictionary = batch_shortest_paths_no_path(G_ig, special_nodes, index_to_node, node_to_index, node_to_muni)  # <<< CHANGED (use igraph)\n",
    "\n",
    "    new_risk = compute_risk_factor_2(T_P_dictionary, T_NP_dictionary)\n",
    "    delta_risk = new_risk - base_risk\n",
    "\n",
    "    edge_risks.append(((u, v), delta_risk))\n",
    "\n",
    "    # Re-add the edge with original weight\n",
    "    G_ig.add_edges([(u_idx, v_idx)])  # <<< NEW (re-add edge)\n",
    "    G_ig.es[-1]['weight'] = edge_weights[(u_idx, v_idx)]  # <<< NEW (set original weight)\n",
    "\n",
    "    # Print progress (overwrite line)\n",
    "    percent_complete = (i) / total * 100\n",
    "    print(f\"\\rProgress: {percent_complete:.2f}% ({i}/{total})\", end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "edge_risks.sort(key=lambda x: x[1], reverse=True)\n",
    "edge_risks_json = [ {\"edge\": [u, v], \"delta_risk\": delta_risk} for (u, v), delta_risk in edge_risks ]\n",
    "with open(\"processed_files/edge_risks_NP.json\", \"w\") as f:\n",
    "    json.dump(edge_risks_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert reduced graph to igraph\n",
    "G_ig_dana, node_to_index, index_to_node, _ = convert_nx_to_igraph(\n",
    "    flood_graph_var[\"DANA_31_10_2024\"], weight_attr='travel_time')\n",
    "\n",
    "# Step 2: Prepare special node indices\n",
    "special_indices = [node_to_index[n] for n in special_nodes]\n",
    "\n",
    "# Step 3: Compute baseline risk for reduced graph\n",
    "T_P_dictionary = batch_shortest_paths(\n",
    "    G_ig_dana, special_nodes, index_to_node, node_to_index, node_to_muni, compute_path=False)\n",
    "\n",
    "base_risk = compute_risk_factor(\n",
    "    T_P_dictionaries[\"DANA_31_10_2024\"], T_NP_dictionary)\n",
    "\n",
    "# Step 4: Prepare candidate edges (only in flood zone)\n",
    "candidate_edges = flood_edges_var[\"DANA_31_10_2024\"]\n",
    "candidate_edges = candidate_edges[candidate_edges['in_flood_zone'].astype(bool)].copy()\n",
    "\n",
    "edge_risks = []\n",
    "total = len(candidate_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "\n",
    "# Step 5: Loop through candidate edges and evaluate impact\n",
    "for i, ((u, v, _), row) in enumerate(candidate_edges.iterrows()):\n",
    "    weight = row['travel_time']\n",
    "\n",
    "    if u not in node_to_index or v not in node_to_index:\n",
    "        continue\n",
    "\n",
    "    u_idx, v_idx = node_to_index[u], node_to_index[v]\n",
    "\n",
    "    # Add edge\n",
    "    G_ig_dana.add_edges([(u_idx, v_idx)])\n",
    "    eid = G_ig_dana.get_eid(u_idx, v_idx, directed=True, error=False)\n",
    "    if eid == -1:\n",
    "        continue\n",
    "\n",
    "    G_ig_dana.es[eid]['weight'] = weight\n",
    "\n",
    "    # Recompute risk\n",
    "    T_P_dictionary = batch_shortest_paths_no_path(G_ig_dana, special_nodes, index_to_node, node_to_index, node_to_muni)\n",
    "    new_risk = compute_risk_factor_2(T_P_dictionary, T_NP_dictionary)\n",
    "    delta_risk = new_risk - base_risk\n",
    "\n",
    "    edge_risks.append(((u, v), delta_risk))\n",
    "\n",
    "    # Remove the edge\n",
    "    G_ig_dana.delete_edges(eid)\n",
    "\n",
    "    # Print progress\n",
    "    percent_complete = (i + 1) / total * 100\n",
    "    print(f\"\\rProgress: {percent_complete:.2f}% ({i + 1}/{total})\", end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "edge_risks.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "edge_risks_json = [ {\"edge\": [u, v], \"delta_risk\": delta_risk} for (u, v), delta_risk in edge_risks ]\n",
    "with open(\"processed_files/edge_risks_DANA.json\", \"w\") as f:\n",
    "    json.dump(edge_risks_json, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = dict(sorted(R.items(), key=lambda item: item[1]))\n",
    "keys = list(R.keys())\n",
    "values = list(R.values())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(keys, values, color=\"Blue\", alpha=0.5)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('R')\n",
    "plt.title('Risk Factor')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('processed_files/Risk_Factor.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = {\n",
    "    # yr values — warm and spaced\n",
    "    \"10 yr\": \"#FFD700\",    # Gold\n",
    "    \"100 yr\": \"#FF7F00\",   # Dark Orange\n",
    "    \"500 yr\": \"#B22222\",   # Firebrick \n",
    "\n",
    "    # DANA values — distinct, avoiding orange/red hues\n",
    "    \"DANA_31_10_2024\": \"#8A2BE2\",  # Blue-Violet\n",
    "    \"DANA_03_11_2024\": \"#FF1493\",  # Deep Pink\n",
    "    \"DANA_05_11_2024\": \"#00CED1\",  # Dark Turquoise\n",
    "    \"DANA_06_11_2024\": \"#32CD32\",  # Lime Green\n",
    "    \"DANA_08_11_2024\": \"#1E90FF\",  # Dodger Blue\n",
    "\n",
    "    # Normal condition\n",
    "    \"Normal Conditions\": \"#808080\"  # Grey\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# --- Prepare data ---\n",
    "plot_data = []\n",
    "zero_counts = {}\n",
    "all_counts = {}\n",
    "layer_names = [\"10 yr\", \"100 yr\", \"500 yr\"]\n",
    "\n",
    "# T_P_lists scenarios\n",
    "for name, results_dict in T_P_dictionaries.items():\n",
    "    if name in layer_names:\n",
    "        travel_times = [v[1] for v in results_dict.values()]\n",
    "        non_zero_times = [t / 60 for t in travel_times if t > 0]\n",
    "        all_times = [t / 60 for t in travel_times]\n",
    "        zero_counts[name] = travel_times.count(0)\n",
    "        all_counts[name] = len(travel_times)\n",
    "        plot_data.append((name, non_zero_times))\n",
    "\n",
    "# Add normal scenario\n",
    "normal_travel_times = [v[1] for v in T_NP_dictionary.values()]\n",
    "normal_non_zero = [t / 60 for t in normal_travel_times if t > 0]\n",
    "normal_total = len(normal_travel_times)\n",
    "plot_data.append((\"Normal Conditions\", normal_non_zero))\n",
    "all_counts[\"Normal Conditions\"] = normal_total\n",
    "zero_counts[\"Normal Conditions\"] = normal_travel_times.count(0)\n",
    "\n",
    "# --- KDE Plot ---\n",
    "fig, (ax_kde, ax_bar) = plt.subplots(1, 2, figsize=(14, 7), gridspec_kw={'width_ratios': [2.5, 1]})\n",
    "\n",
    "x_vals = np.linspace(0, max([max(times) if times else 0 for _, times in plot_data]), 500)\n",
    "\n",
    "for name, times in plot_data:\n",
    "    if len(times) > 1:\n",
    "        kde = gaussian_kde(times)\n",
    "        y = kde(x_vals)\n",
    "        ratio = len(times) / all_counts[name] if all_counts[name] > 0 else 0\n",
    "        y_rescaled = y * ratio\n",
    "        color = color_palette.get(name, 'gray')  # fallback to gray if not defined\n",
    "        ax_kde.plot(x_vals, y_rescaled, label=name, color=color)\n",
    "\n",
    "ax_kde.set_title(\"PDF of Travel Times\")\n",
    "ax_kde.set_xlabel(\"Travel Time (minutes)\")\n",
    "ax_kde.grid(True)\n",
    "ax_kde.legend(loc='upper right')\n",
    "\n",
    "# --- Reachability Bar Chart ---\n",
    "scenarios = layer_names + [\"Normal Conditions\"]\n",
    "reachable = [(all_counts[n] - zero_counts[n]) / all_counts[n] if all_counts[n] > 0 else 0 for n in scenarios]\n",
    "unreachable = [1 - r for r in reachable]\n",
    "\n",
    "bar_positions = np.arange(len(scenarios))\n",
    "ax_bar.barh(bar_positions, unreachable, color='salmon', label='Unreachable')\n",
    "ax_bar.barh(bar_positions, reachable, left=unreachable, color='mediumseagreen', label='Reachable')\n",
    "\n",
    "ax_bar.set_yticks(bar_positions)\n",
    "ax_bar.set_yticklabels(scenarios)\n",
    "ax_bar.set_xlim(0, 1)\n",
    "ax_bar.set_title(\"Fraction of cut routes\")\n",
    "ax_bar.set_xlabel(\"Proportion\")\n",
    "#ax_bar.legend(loc='lower right')\n",
    "ax_bar.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax_bar.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('processed_files/Travel_times_yr.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Prepare data ---\n",
    "plot_data = []\n",
    "zero_counts = {}\n",
    "all_counts = {}\n",
    "layer_names = [\"DANA_31_10_2024\",\"DANA_03_11_2024\",\"DANA_05_11_2024\",\"DANA_06_11_2024\",\"DANA_08_11_2024\"]\n",
    "\n",
    "# T_P_lists scenarios\n",
    "for name, results_dict in T_P_dictionaries.items():\n",
    "    if name in layer_names:\n",
    "        travel_times = [v[1] for v in results_dict.values()]\n",
    "        non_zero_times = [t / 60 for t in travel_times if t > 0]\n",
    "        all_times = [t / 60 for t in travel_times]\n",
    "        zero_counts[name] = travel_times.count(0)\n",
    "        all_counts[name] = len(travel_times)\n",
    "        plot_data.append((name, non_zero_times))\n",
    "\n",
    "# Add normal scenario\n",
    "normal_travel_times = [v[1] for v in T_NP_dictionary.values()]\n",
    "normal_non_zero = [t / 60 for t in normal_travel_times if t > 0]\n",
    "normal_total = len(normal_travel_times)\n",
    "plot_data.append((\"Normal Conditions\", normal_non_zero))\n",
    "all_counts[\"Normal Conditions\"] = normal_total\n",
    "zero_counts[\"Normal Conditions\"] = normal_travel_times.count(0)\n",
    "\n",
    "# --- KDE Plot ---\n",
    "fig, (ax_kde, ax_bar) = plt.subplots(1, 2, figsize=(14, 7), gridspec_kw={'width_ratios': [2.5, 1]})\n",
    "\n",
    "x_vals = np.linspace(0, max([max(times) if times else 0 for _, times in plot_data]), 500)\n",
    "\n",
    "for name, times in plot_data:\n",
    "    if len(times) > 1:\n",
    "        kde = gaussian_kde(times)\n",
    "        y = kde(x_vals)\n",
    "        ratio = len(times) / all_counts[name] if all_counts[name] > 0 else 0\n",
    "        y_rescaled = y * ratio\n",
    "        color = color_palette.get(name, 'gray')  # fallback to gray if not defined\n",
    "        ax_kde.plot(x_vals, y_rescaled, label=name, color=color)\n",
    "\n",
    "ax_kde.set_title(\"PDF of Travel Times\")\n",
    "ax_kde.set_xlabel(\"Travel Time (minutes)\")\n",
    "ax_kde.grid(True)\n",
    "ax_kde.legend(loc='upper right')\n",
    "\n",
    "# --- Reachability Bar Chart ---\n",
    "scenarios = layer_names + [\"Normal Conditions\"]\n",
    "reachable = [(all_counts[n] - zero_counts[n]) / all_counts[n] if all_counts[n] > 0 else 0 for n in scenarios]\n",
    "unreachable = [1 - r for r in reachable]\n",
    "\n",
    "bar_positions = np.arange(len(scenarios))\n",
    "ax_bar.barh(bar_positions, unreachable, color='salmon', label='Unreachable')\n",
    "ax_bar.barh(bar_positions, reachable, left=unreachable, color='mediumseagreen', label='Reachable')\n",
    "\n",
    "ax_bar.set_yticks(bar_positions)\n",
    "ax_bar.set_yticklabels(scenarios)\n",
    "ax_bar.set_xlim(0, 1)\n",
    "ax_bar.set_title(\"Fraction of cut routes\")\n",
    "ax_bar.set_xlabel(\"Proportion\")\n",
    "#ax_bar.legend(loc='lower right')\n",
    "ax_bar.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax_bar.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('processed_files/Travel_times_DANA.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59NZ-jYDAeVF"
   },
   "source": [
    "# Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial position\n",
    "projected = study_area.to_crs(epsg=25830)\n",
    "centroid_projected = projected.geometry.centroid.iloc[0]\n",
    "centroid_latlon = gpd.GeoSeries([centroid_projected], crs=25830).to_crs(epsg=4326).geometry.iloc[0]\n",
    "map_center = [centroid_latlon.y, centroid_latlon.x]\n",
    "bounds_wgs84 = study_area.to_crs(epsg=4326).total_bounds\n",
    "map_bounds = [[bounds_wgs84[1], bounds_wgs84[0]], [bounds_wgs84[3], bounds_wgs84[2]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Areas at Risk and DANA Area (with roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m_1.fit_bounds(map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(graph_path):\n",
    "    logging.info(\"Loading saved road network graph...\")\n",
    "    G = ox.load_graphml(graph_path)\n",
    "else:\n",
    "    logging.info(\"Downloading road network...\")\n",
    "    G = ox.graph_from_polygon(polygon, network_type=\"drive\", simplify=True)\n",
    "    ox.save_graphml(G, filepath=graph_path)\n",
    "    logging.info(\"Graph saved.\")\n",
    "\n",
    "nodes, edges = ox.graph_to_gdfs(G)\n",
    "logging.info(\"Converted graph to GeoDataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flood zones\n",
    "add_flood_zone_layer(\"10 yr\", m_1)\n",
    "add_flood_zone_layer(\"100 yr\", m_1)\n",
    "add_flood_zone_layer(\"500 yr\", m_1)\n",
    "add_flood_zone_layer(\"DANA_31_10_2024\", m_1)\n",
    "    \n",
    "# Add flooded roads (optional)\n",
    "add_roads_layer(\"10 yr\", m_1, True)\n",
    "add_roads_layer(\"100 yr\", m_1, True)\n",
    "add_roads_layer(\"500 yr\", m_1, True)\n",
    "add_roads_layer(\"DANA_31_10_2024\", m_1, True)\n",
    "add_roads_layer(\"Normal Conditions\", m_1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.LayerControl(collapsed=False).add_to(m_1)\n",
    "m_1.save(\"processed_files/Risk_max_DANA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANA flood depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_2 = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m_2.fit_bounds(map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=depth_zones[\"DANA_31_10_2024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = depth[\"depth_val\"].min()\n",
    "max_depth = depth[\"depth_val\"].max()\n",
    "depth_colormap = linear.YlGnBu_09.scale(min_depth, max_depth)\n",
    "depth_colormap.caption = 'Flood Depth (m)'\n",
    "\n",
    "folium.GeoJson(\n",
    "    depth,\n",
    "    name=\"DANA flood depth\",\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': depth_colormap(feature['properties']['depth_val']),\n",
    "        'color': 'black',\n",
    "        'weight': 0.5,\n",
    "        'fillOpacity': 0.7\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"depth_val\"], aliases=[\"Depth (m):\"])\n",
    ").add_to(m_2)\n",
    "\n",
    "depth_colormap.add_to(m_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.LayerControl(collapsed=False).add_to(m_2)\n",
    "m_2.save(\"processed_files/Max_flood_depth.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DANA Flooded Area Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_3 = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m_3.fit_bounds(map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flood zones\n",
    "add_flood_zone_layer(\"DANA_31_10_2024\", m_3)\n",
    "add_flood_zone_layer(\"DANA_03_11_2024\", m_3)\n",
    "add_flood_zone_layer(\"DANA_05_11_2024\", m_3)\n",
    "add_flood_zone_layer(\"DANA_06_11_2024\", m_3)\n",
    "add_flood_zone_layer(\"DANA_08_11_2024\", m_3)\n",
    "    \n",
    "# Add flooded roads (optional)\n",
    "add_roads_layer(\"DANA_31_10_2024\", m_3, True)\n",
    "add_roads_layer(\"DANA_03_11_2024\", m_3, True)\n",
    "add_roads_layer(\"DANA_05_11_2024\", m_3, True)\n",
    "add_roads_layer(\"DANA_06_11_2024\", m_3, True)\n",
    "add_roads_layer(\"DANA_08_11_2024\", m_3, True)\n",
    "add_roads_layer(\"Normal Conditions\", m_3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.LayerControl(collapsed=False).add_to(m_3)\n",
    "m_3.save(\"processed_files/DANA_evolution.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_files/edge_risks_NP.json\", \"r\") as f:\n",
    "    delta_risks1 = json.load(f)\n",
    "with open(\"processed_files/edge_risks_DANA.json\", \"r\") as f:\n",
    "    delta_risks2 = json.load(f)\n",
    "\n",
    "# === Build delta dicts ===\n",
    "def build_delta_dict(delta_list):\n",
    "    return {\n",
    "        tuple(item['edge']): item['delta_risk']\n",
    "        for item in delta_list\n",
    "    }\n",
    "\n",
    "delta_dict1 = build_delta_dict(delta_risks1)\n",
    "delta_dict2 = build_delta_dict(delta_risks2)\n",
    "\n",
    "# === Signed log transform ===\n",
    "def signed_log_transform(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return 1/(np.sign(x) * np.log10(abs(x)))\n",
    "\n",
    "# === Get max absolute log ===\n",
    "all_values = list(delta_dict1.values()) + list(delta_dict2.values())\n",
    "transformed_values = [signed_log_transform(v) for v in all_values if v is not None]\n",
    "max_abs_log = max(abs(val) for val in transformed_values)\n",
    "\n",
    "# === Create custom diverging colormap ===\n",
    "def inverted_colormap(val):\n",
    "    \"\"\"\n",
    "    Maps log-transformed delta to color:\n",
    "    - stronger values (larger abs(val)) → stronger color (closer to red/blue)\n",
    "    - near-zero values → white\n",
    "    \"\"\"\n",
    "    if val == 0:\n",
    "        return \"#ffffff\"\n",
    "    \n",
    "    norm_val = signed_log_transform(val) / max_abs_log\n",
    "    abs_norm = abs(norm_val)\n",
    "\n",
    "    # invert strength: low abs → white, high abs → strong\n",
    "    strength = abs_norm\n",
    "    if norm_val > 0:\n",
    "        # red side\n",
    "        return cm.linear.Reds_09.scale(0, 1)(strength)\n",
    "    else:\n",
    "        # blue side\n",
    "        return cm.linear.Blues_09.scale(0, 1)(strength)\n",
    "\n",
    "# === Colorbar (caption only; not linked directly) ===\n",
    "legend_colormap = cm.LinearColormap(\n",
    "    colors=[\"blue\", \"white\", \"red\"],\n",
    "    vmin=-max_abs_log,\n",
    "    vmax=+max_abs_log\n",
    ")\n",
    "legend_colormap.caption = \"Δ Risk (Signed Log Scale, Stronger = Darker)\"\n",
    "\n",
    "# === Add edges to map ===\n",
    "def add_edges_to_map(fmap, edges, delta_dict, label, filter_flood=False):\n",
    "    fg = folium.FeatureGroup(name=label)\n",
    "\n",
    "    for idx, row in edges.iterrows():\n",
    "        edge_key = (row['u'], row['v']) if 'u' in row and 'v' in row else (idx[0], idx[1])\n",
    "\n",
    "        if filter_flood and not row.get(\"in_flood_zone\", False):\n",
    "            continue\n",
    "\n",
    "        value = delta_dict.get(edge_key)\n",
    "        if value is None:\n",
    "            continue\n",
    "\n",
    "        # Determine color\n",
    "        if value == 0:\n",
    "            color = \"#bbbbbb\"\n",
    "            opacity = 0.4\n",
    "            weight = 1\n",
    "        else:\n",
    "            color = inverted_colormap(value)\n",
    "            opacity = 0.8\n",
    "            weight = 2\n",
    "\n",
    "        coords = [(lat, lon) for lon, lat in row.geometry.coords]\n",
    "\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=color,\n",
    "            weight=weight,\n",
    "            opacity=opacity,\n",
    "            tooltip=f\"{edge_key} | Δ Risk: {value:.1e}\"\n",
    "        ).add_to(fg)\n",
    "\n",
    "    fg.add_to(fmap)\n",
    "\n",
    "# === Build map ===\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m.fit_bounds(map_bounds)\n",
    "\n",
    "add_edges_to_map(m, edges, delta_dict1, label=\"All Roads\")\n",
    "add_edges_to_map(m, flood_edges_var[\"DANA_31_10_2024\"], delta_dict2, label=\"DANA_31_10_2024\", filter_flood=True)\n",
    "\n",
    "m.add_child(legend_colormap)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save(\"processed_files/delta_risk_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping\n",
    "colormap = linear.YlOrRd_09.scale(0, 1)  # Yellow to red\n",
    "colormap.caption = 'Risk Index'\n",
    "\n",
    "# Create base map\n",
    "map_center = [\n",
    "    sum([df['lat'].mean() for df in polygons]) / len(polygons),\n",
    "    sum([df['lon'].mean() for df in polygons]) / len(polygons)\n",
    "]\n",
    "m = folium.Map(location=map_center, zoom_start=7, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add municipality polygons with color-coded fill\n",
    "for gdf in polygons:\n",
    "    name = gdf['name'].iloc[0]\n",
    "    if name == \"Valencia\":\n",
    "        name= \"València\"\n",
    "    geometry = gdf['geometry'].iloc[0]\n",
    "    value = compute_municipal_risk_factor(T_P_dictionaries[\"DANA_31_10_2024\"], T_NP_dictionary, name)\n",
    "    color = colormap(value)\n",
    "\n",
    "    geo_json = mapping(geometry)\n",
    "    folium.GeoJson(\n",
    "        geo_json,\n",
    "        tooltip=folium.Tooltip(f\"{name}: {value:.2f}\"),\n",
    "        style_function=lambda feature, color=color: {\n",
    "            'fillColor': color,\n",
    "            'color': 'black',\n",
    "            'weight': 1,\n",
    "            'fillOpacity': 0.7\n",
    "        }\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add label at centroid\n",
    "    centroid = geometry.centroid\n",
    "    folium.Marker(\n",
    "        location=[centroid.y, centroid.x],\n",
    "        icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 10pt; color: black;\">{name}</div>\"\"\")\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add color map legend\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Display map\n",
    "m.save(\"processed_files/municipality_risk_map.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (oxenv)",
   "language": "python",
   "name": "oxenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
