{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8ZNNXRwxJ9L",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg--Mw_xeuKa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import fiona\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "import folium\n",
    "from folium import GeoJson, LayerControl\n",
    "from branca.colormap import linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_flooded_roads(edges, nodes, flood_zones, layer):\n",
    "    output_path = flood_cut_roads[layer]\n",
    "    graphml_path = flood_safe_roads[layer]\n",
    "\n",
    "    if os.path.exists(output_path) and layer in fiona.listlayers(output_path):\n",
    "        print(f\"Loading {layer} from {output_path}\")\n",
    "        edges = gpd.read_file(output_path, layer=layer)\n",
    "    else:\n",
    "        print(f\"Tagging and saving {layer} to {output_path}\")\n",
    "\n",
    "        bounds = edges.total_bounds\n",
    "        flood_subset = flood_zones.cx[bounds[0]:bounds[2], bounds[1]:bounds[3]]\n",
    "        flood_geoms = flood_subset.geometry\n",
    "\n",
    "        edges = edges.copy()\n",
    "        edges[\"in_flood_zone\"] = edges.geometry.apply(lambda geom: flood_geoms.intersects(geom).any())\n",
    "\n",
    "        edges.to_file(output_path, layer=layer, driver=\"GPKG\")\n",
    "\n",
    "    if os.path.exists(graphml_path):\n",
    "        print(\"Pruned graph already exists\")\n",
    "    else:    \n",
    "        safe_edges = edges[~edges[\"in_flood_zone\"]].copy()\n",
    "        \n",
    "        # Rebuild graph from safe edges\n",
    "        print(\"Rebuilding pruned graph...\")\n",
    "        G_safe = ox.graph_from_gdfs(nodes, safe_edges)\n",
    "        ox.save_graphml(G_safe, filepath=graphml_path)\n",
    "        print(f\"Saved pruned graph to {graphml_path}\")\n",
    "\n",
    "    return edges, G_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_clip_flood_zone(return_crs, layer, source_path, clip_geom):\n",
    "    output_path = flood_zones[layer]\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Loading {layer} from {output_path}\")\n",
    "        clipped = gpd.read_file(output_path, layer=layer).to_crs(return_crs)\n",
    "    else:\n",
    "        # Clip and save the original\n",
    "        print(f\"Clipping and saving {layer} from {output_path}\" )\n",
    "        flood = gpd.read_file(source_path).to_crs(return_crs)\n",
    "        clipped = gpd.clip(flood, clip_geom)\n",
    "        clipped.to_file(output_path, layer=layer, driver=\"GPKG\")\n",
    "\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_geojson_safe(gdf):\n",
    "    gdf = gdf.copy()\n",
    "    dt_cols = gdf.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]']).columns\n",
    "    gdf[dt_cols] = gdf[dt_cols].astype(str)\n",
    "    for col in gdf.columns:\n",
    "        if col != \"geometry\" and not pd.api.types.is_scalar(gdf[col].iloc[0]):\n",
    "            gdf.drop(columns=[col], inplace=True)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flood_zone_layer(gdf, name, color, m):\n",
    "    if gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    gdf_serializable = make_geojson_safe(gdf)\n",
    "\n",
    "    style_function = lambda x: {\n",
    "        'fillColor': color,\n",
    "        'color': color,\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.4\n",
    "    }\n",
    "\n",
    "    geojson = folium.GeoJson(\n",
    "        data=gdf_serializable,\n",
    "        name=f\"Flood {name}\",\n",
    "        style_function=style_function,\n",
    "        show=False\n",
    "    )\n",
    "    geojson.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flooded_roads_layer(edges, name, color, m):\n",
    "    flooded = edges[edges[\"in_flood_zone\"] == True]\n",
    "    flooded = flooded.to_crs(epsg=4326)\n",
    "    flooded = make_geojson_safe(flooded)\n",
    "\n",
    "    style_function = lambda x: {\n",
    "        'color': color,\n",
    "        'weight': 2,\n",
    "        'opacity': 0.8\n",
    "    }\n",
    "\n",
    "    geojson = folium.GeoJson(\n",
    "        flooded,\n",
    "        name=f\"Flooded Roads {name}\",\n",
    "        style_function=style_function,\n",
    "        show=False\n",
    "    )\n",
    "    geojson.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_roads_layer(edges, name, color, m):\n",
    "    roads = edges.copy()\n",
    "    roads = roads.to_crs(epsg=4326)\n",
    "    roads = make_geojson_safe(roads)\n",
    "\n",
    "    style_function = lambda x: {\n",
    "        'color': color,\n",
    "        'weight': 2,\n",
    "        'opacity': 0.8\n",
    "    }\n",
    "\n",
    "    geojson = folium.GeoJson(\n",
    "        roads,\n",
    "        name=f\"{name}\",\n",
    "        style_function=style_function,\n",
    "        show=False\n",
    "    )\n",
    "    geojson.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_depth_range(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "\n",
    "    val = val.strip()\n",
    "\n",
    "    if val.startswith('Below'):\n",
    "        return float(val[5:].strip()) / 2\n",
    "\n",
    "    if val.startswith('>'):\n",
    "        return float(val[1:].strip())  # You may want to cap it\n",
    "\n",
    "    if '-' in val:\n",
    "        parts = val.split('-')\n",
    "        try:\n",
    "            low = float(parts[0].strip())\n",
    "            high = float(parts[1].strip())\n",
    "            return (low + high) / 2\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_length(G, source, target, node_to_muni):\n",
    "    try:\n",
    "        path = nx.shortest_path(G, source=source, target=target, weight='length')\n",
    "        total_length = nx.shortest_path_length(G, source=source, target=target, weight='length')\n",
    "        key = f\"{node_to_muni[source]}__{node_to_muni[target]}\"\n",
    "\n",
    "    except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "        print(f\"No path between {source} and {target} ({node_to_muni[source]} - {node_to_muni[target]})\")\n",
    "        path = \"\"\n",
    "        total_length = 0\n",
    "        key = f\"{node_to_muni[source]}__{node_to_muni[target]}\"\n",
    "    return key, path, total_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shortest_paths(G, output_dir, path_filename):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    municipal_nodes = [node for node, data in G.nodes(data=True) if data.get(\"municipality\")]\n",
    "    municipal_nodes = sorted(municipal_nodes)\n",
    "    node_to_muni = {node: G.nodes[node]['municipality'] for node in municipal_nodes}\n",
    "    path_path = os.path.join(output_dir, path_filename)\n",
    "    \n",
    "    if os.path.exists(path_path):\n",
    "        logging.info(f\"Shortest paths already calculated at {path_path}\")\n",
    "        return\n",
    "    \n",
    "    logging.info(f\"Calculating shortest paths between all municipalities for graph...\")\n",
    "    \n",
    "    paths_dict = {}\n",
    "    for source, target in combinations(municipal_nodes, 2):\n",
    "        key, path, length = shortest_path_length(G, source, target, node_to_muni)\n",
    "        paths_dict[key] = {\n",
    "            \"nodes\": path,\n",
    "            \"total_length\": length\n",
    "        }\n",
    "    \n",
    "    with open(path_path, \"w\") as f:\n",
    "        json.dump(paths_dict, f, indent=2)\n",
    "    \n",
    "    logging.info(f\"Saved shortest paths to {path_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae_V4hjCAsN8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Street data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPYUcbX01Hvy"
   },
   "outputs": [],
   "source": [
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_path = os.path.join(output_dir, \"study_area.geojson\")\n",
    "graph_path = os.path.join(output_dir, \"tagged_graph.graphml\")\n",
    "\n",
    "valencia_municipalities = [\n",
    "    \"Alaquàs\", \"Albal\", \"Albalat de la Ribera\", \"Alberic\", \"Alborache\", \"Alcàsser\", \"l'Alcúdia\",\n",
    "    \"Aldaia\", \"Alfafar\", \"Alfarb\", \"Algemesí\", \"Alginet\", \"Almussafes\", \"Alzira\",\n",
    "    \"Benetússer\", \"Benicull de Xúquer\", \"Benifaió\", \"Beniparrell\", \"Benimodo\", \"Bétera\",\n",
    "    \"Bugarra\", \"Buñol\", \"Calles\", \"Camporrobles\", \"Carcaixent\", \"Carlet\", \"Catadau\", \"Catarroja\",\n",
    "    \"Caudete de las Fuentes\", \"Chera\", \"Cheste\", \"Chiva\", \"Chulilla\", \"Corbera\", \"Cullera\",\n",
    "    \"Dos Aguas\", \"Favara\", \"Fortaleny\", \"Fuenterrobles\", \"Gestalgar\", \"Godelleta\", \"Guadassuar\",\n",
    "    \"l'Ènova\", \"Llaurí\", \"Llombai\", \"Llíria\", \"Llocnou de la Corona\", \"Loriguilla\", \"Macastre\",\n",
    "    \"Manises\", \"Manuel\", \"Massanassa\", \"Millares\", \"Mislata\", \"Montroi\", \"Montserrat\", \"Paiporta\",\n",
    "    \"Paterna\", \"Pedralba\", \"Picanya\", \"Picassent\", \"Polinyà de Xúquer\", \"La Pobla Llarga\",\n",
    "    \"Quart de Poblet\", \"Rafelguaraf\", \"Real\", \"Requena\", \"Riba-roja de Túria\", \"Riola\", \"Sedaví\",\n",
    "    \"Senyera\", \"Siete Aguas\", \"Silla\", \"Sinarcas\", \"Sollana\", \"Sot de Chera\", \"Sueca\",\n",
    "    \"Tavernes de la Valldigna\", \"Torrent\", \"Tous\", \"Turís\", \"Utiel\", \"València\", \"Vilamarxant\", \"Xirivella\",\n",
    "    \"Yátova\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(polygon_path):\n",
    "    logging.info(\"Loading saved study area polygon...\")\n",
    "    study_area = gpd.read_file(polygon_path)\n",
    "else:\n",
    "    logging.info(\"Downloading polygons for municipalities...\")\n",
    "    polygons = []\n",
    "\n",
    "    for municipality in valencia_municipalities:\n",
    "        try:\n",
    "            place_name = f\"{municipality}, Valencia, Spain\"\n",
    "            gdf = ox.geocode_to_gdf(place_name)\n",
    "\n",
    "            if gdf.crs != \"EPSG:4326\":\n",
    "                gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "            polygons.append(gdf)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error retrieving {municipality}: {e}\", exc_info=True)\n",
    "\n",
    "    # Add Mira from Cuenca (just in case)\n",
    "    try:\n",
    "        gdf = ox.geocode_to_gdf(\"Mira, Cuenca, Spain\")\n",
    "        if gdf.crs != \"EPSG:4326\":\n",
    "            gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "        polygons.append(gdf)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error retrieving Mira: {e}\", exc_info=True)\n",
    "\n",
    "    study_area = gpd.GeoDataFrame(pd.concat(polygons, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    study_area = study_area[study_area.geometry.notnull()]\n",
    "    study_area.to_file(polygon_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_area = study_area[study_area.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "polygon = unary_union(study_area.geometry)\n",
    "logging.info(\"Polygon geometry union complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(graph_path):\n",
    "    logging.info(\"Loading saved road network graph...\")\n",
    "    G = ox.load_graphml(graph_path)\n",
    "else:\n",
    "    logging.info(\"Downloading road network...\")\n",
    "    G = ox.graph_from_polygon(polygon, network_type=\"drive\", simplify=True)\n",
    "    ox.save_graphml(G, filepath=graph_path)\n",
    "    logging.info(\"Graph saved.\")\n",
    "\n",
    "nodes, edges = ox.graph_to_gdfs(G)\n",
    "logging.info(\"Converted graph to GeoDataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "if 'municipality' not in nodes.columns:\n",
    "    logging.info(\"Adding 'municipality' field to nodes...\")\n",
    "\n",
    "    nodes['municipality'] = \"\"\n",
    "\n",
    "    node_coords = np.array([(geom.y, geom.x) for geom in nodes.geometry])\n",
    "    kdtree = cKDTree(node_coords)\n",
    "\n",
    "    for _, row in study_area.iterrows():\n",
    "        name = row.get(\"name\") or row.get(\"display_name\") or \"unknown\"\n",
    "        geom = row.geometry\n",
    "\n",
    "        if not geom or not geom.is_valid or name == \"Favara\":\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            muni_graph = ox.graph_from_polygon(geom, network_type='drive', simplify=True)\n",
    "            center_node = ox.distance.nearest_nodes(muni_graph, X=geom.centroid.x, Y=geom.centroid.y)\n",
    "            center_point = Point((muni_graph.nodes[center_node]['x'], muni_graph.nodes[center_node]['y']))\n",
    "            _, idx = kdtree.query([center_point.y, center_point.x], k=1)\n",
    "            nearest_node_idx = nodes.index[idx]\n",
    "            nodes.at[nearest_node_idx, 'municipality'] = name\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not process {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    for node_id, row in nodes.iterrows():\n",
    "        G.nodes[node_id]['municipality'] = row['municipality']\n",
    "\n",
    "    graph_path = os.path.join(output_dir, \"tagged_graph.graphml\")\n",
    "    ox.save_graphml(G, graph_path)\n",
    "    logging.info(f\"Updated graph saved to: {graph_path}\")\n",
    "\n",
    "else:\n",
    "    logging.info(\"'municipality' field already exists in nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_shortest_paths(G, output_dir, path_filename=\"shortest_paths_length.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail=False\n",
    "if rail:\n",
    "    graph_path_rail = os.path.join(output_dir, \"study_area_rail.graphml\")\n",
    "    if os.path.exists(graph_path_rail):\n",
    "        print(\"Loading saved rail network graph...\")\n",
    "        G_rail = ox.load_graphml(graph_path_rail)\n",
    "    else:\n",
    "        print(\"Downloading rail network graph...\")\n",
    "        rail_filter = '[\"railway\"~\"rail|light_rail|subway|tram\"]'\n",
    "        G_rail = ox.graph_from_polygon(polygon, custom_filter=rail_filter, network_type=\"all\")\n",
    "        ox.save_graphml(G_rail, filepath=graph_path_rail)\n",
    "\n",
    "    nodes_rail, edges_rail = ox.graph_to_gdfs(G_rail)\n",
    "    del G_rail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_zones = {\n",
    "    \"10 yr\": f\"{output_dir}/flood_risk_zone_10.gpkg\",\n",
    "    \"100 yr\": f\"{output_dir}/flood_risk_zone_100.gpkg\",\n",
    "    \"500 yr\": f\"{output_dir}/flood_risk_zone_500.gpkg\",\n",
    "    \"DANA_02_11_2024\": f\"{output_dir}/DANA_zone_02_11_2024.gpkg\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/DANA_zone_03_11_2024.gpkg\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/DANA_zone_06_11_2024.gpkg\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/DANA_zone_08_11_2024.gpkg\",\n",
    "    \"DANA depth\": f\"{output_dir}/DANA_depths.gpkg\"\n",
    "}\n",
    "\n",
    "flood_cut_roads = {\n",
    "    \"10 yr\": f\"{output_dir}/flood_risk_cut_roads_10.gpkg\",\n",
    "    \"100 yr\": f\"{output_dir}/flood_risk_cut_roads_100.gpkg\",\n",
    "    \"500 yr\": f\"{output_dir}/flood_risk_cut_roads_500.gpkg\",\n",
    "    \"DANA_02_11_2024\": f\"{output_dir}/DANA_cut_roads_02_11_2024.gpkg\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/DANA_cut_roads_03_11_2024.gpkg\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/DANA_cut_roads_06_11_2024.gpkg\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/DANA_cut_roads_08_11_2024.gpkg\"\n",
    "}\n",
    "\n",
    "flood_safe_roads = {\n",
    "    \"10 yr\": f\"{output_dir}/flood_risk_10_safe_roads.graphml\",\n",
    "    \"100 yr\": f\"{output_dir}/flood_risk__100_safe_roads.graphml\",\n",
    "    \"500 yr\": f\"{output_dir}/flood_risk__500_safe_roads.graphml\",\n",
    "    \"DANA_02_11_2024\": f\"{output_dir}/DANA_safe_roads_02_11_2024.graphml\",\n",
    "    \"DANA_03_11_2024\": f\"{output_dir}/DANA_safe_roads_03_11_2024.graphml\",\n",
    "    \"DANA_06_11_2024\": f\"{output_dir}/DANA_safe_roads_06_11_2024.graphml\",\n",
    "    \"DANA_08_11_2024\": f\"{output_dir}/DANA_safe_roads_08_11_2024.graphml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "im671dntApI-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Floodable zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_risk_zone_10  = load_or_clip_flood_zone(edges.crs, \"10 yr\", \"source_files/laminaspb-q10/Q10_2Ciclo_PB_20241121.shp\", polygon)\n",
    "flood_risk_zone_100 = load_or_clip_flood_zone(edges.crs, \"100 yr\", \"source_files/laminaspb-q100/Q100_2Ciclo_PB_20241121_ETRS89.shp\", polygon)\n",
    "flood_risk_zone_500 = load_or_clip_flood_zone(edges.crs, \"500 yr\", \"source_files/laminaspb-q500/Q500_2Ciclo_PB_20241121_ETRS89.shp\", polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_flood_10, G_flood_10 = tag_flooded_roads(edges, nodes, flood_risk_zone_10, \"10 yr\")\n",
    "edges_flood_100, G_flood_100 = tag_flooded_roads(edges, nodes, flood_risk_zone_100, \"100 yr\")\n",
    "edges_flood_500, G_flood_500 = tag_flooded_roads(edges, nodes, flood_risk_zone_500, \"500 yr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flooded Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_zone_DANA_02_11_2024  = load_or_clip_flood_zone(edges.crs, \"DANA_02_11_2024\", \"source_files/EMSR773_AOI01_DEL_PRODUCT_v1/EMSR773_AOI01_DEL_PRODUCT_observedEventA_v1.shp\", polygon)\n",
    "flood_zone_DANA_03_11_2024  = load_or_clip_flood_zone(edges.crs, \"DANA_03_11_2024\", \"source_files/EMSR773_AOI01_DEL_MONIT01_v1/EMSR773_AOI01_DEL_MONIT01_observedEventA_v1.shp\", polygon)\n",
    "flood_zone_DANA_06_11_2024  = load_or_clip_flood_zone(edges.crs, \"DANA_06_11_2024\", \"source_files/EMSR773_AOI01_DEL_MONIT02_v1/EMSR773_AOI01_DEL_MONIT02_observedEventA_v1.shp\", polygon)\n",
    "flood_zone_DANA_08_11_2024  = load_or_clip_flood_zone(edges.crs, \"DANA_08_11_2024\", \"source_files/EMSR773_AOI01_DEL_MONIT04_v1/EMSR773_AOI01_DEL_MONIT04_observedEventA_v1.shp\", polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_DANA_02_11_2024, G_DANA_02_11_2024 = tag_flooded_roads(edges, nodes, flood_zone_DANA_02_11_2024, \"DANA_02_11_2024\")\n",
    "edges_DANA_03_11_2024, G_DANA_03_11_2024 = tag_flooded_roads(edges, nodes, flood_zone_DANA_03_11_2024, \"DANA_03_11_2024\")\n",
    "edges_DANA_06_11_2024, G_DANA_06_11_2024 = tag_flooded_roads(edges, nodes, flood_zone_DANA_06_11_2024, \"DANA_06_11_2024\")\n",
    "edges_DANA_08_11_2024, G_DANA_08_11_2024 = tag_flooded_roads(edges, nodes, flood_zone_DANA_08_11_2024, \"DANA_08_11_2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = {\n",
    "    \"DANA_02_11_2024\": G_DANA_02_11_2024,\n",
    "    \"DANA_03_11_2024\": G_DANA_03_11_2024,\n",
    "    \"DANA_06_11_2024\": G_DANA_06_11_2024,\n",
    "    \"DANA_08_11_2024\": G_DANA_08_11_2024\n",
    "}\n",
    "\n",
    "\n",
    "for name, graph in graphs.items():\n",
    "    calculate_shortest_paths(graph, output_dir, \"shortest_path_length_\"+name+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer=\"DANA depth\"\n",
    "output_path = flood_zones[layer]\n",
    "\n",
    "if os.path.exists(output_path) and layer in fiona.listlayers(output_path):\n",
    "    print(f\"Loading {layer} from {output_path}\")\n",
    "    DANA_flood_depth=gpd.read_file(output_path, layer=layer)\n",
    "else:\n",
    "    print(f\"Saving {layer} to {output_path}\")\n",
    "    DANA_flood_depth = gpd.read_file(\"source_files/EMSR773_AOI01_DEL_PRODUCT_v1/EMSR773_AOI01_DEL_PRODUCT_floodDepthA_v1.shp\")\n",
    "    DANA_flood_depth[\"depth_val\"] = DANA_flood_depth[\"value\"].apply(parse_depth_range)\n",
    "    DANA_flood_depth.to_file(output_path, layer=layer, driver=\"GPKG\")\n",
    "    print(f\"Saved processed {layer} in {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59NZ-jYDAeVF",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial position\n",
    "projected = study_area.to_crs(epsg=25830)\n",
    "centroid_projected = projected.geometry.centroid.iloc[0]\n",
    "centroid_latlon = gpd.GeoSeries([centroid_projected], crs=25830).to_crs(epsg=4326).geometry.iloc[0]\n",
    "map_center = [centroid_latlon.y, centroid_latlon.x]\n",
    "bounds_wgs84 = study_area.to_crs(epsg=4326).total_bounds\n",
    "map_bounds = [[bounds_wgs84[1], bounds_wgs84[0]], [bounds_wgs84[3], bounds_wgs84[2]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Areas at Risk and DANA Area (with roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_colors = {\n",
    "    \"10 yr\": \"#56B4E9\",   # Sky Blue\n",
    "    \"100 yr\": \"#009E73\",  # Bluish Green\n",
    "    \"500 yr\": \"#E69F00\",  # Orange\n",
    "    \"DANA_02_11_2024\": \"#CC79A7\"  # Reddish Purple\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m_1.fit_bounds(map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flood zones\n",
    "add_flood_zone_layer(flood_risk_zone_10, \"10 yr\", flood_colors[\"10 yr\"], m_1)\n",
    "add_flood_zone_layer(flood_risk_zone_100, \"100 yr\", flood_colors[\"100 yr\"], m_1)\n",
    "add_flood_zone_layer(flood_risk_zone_500, \"500 yr\", flood_colors[\"500 yr\"], m_1)\n",
    "add_flood_zone_layer(flood_zone_DANA_02_11_2024, \"DANA_02_11_2024\", flood_colors[\"DANA_02_11_2024\"], m_1)\n",
    "    \n",
    "# Add flooded roads (optional)\n",
    "add_flooded_roads_layer(edges_flood_10, \"10 yr\", flood_colors[\"10 yr\"], m_1)\n",
    "add_flooded_roads_layer(edges_flood_100, \"100 yr\", flood_colors[\"100 yr\"], m_1)\n",
    "add_flooded_roads_layer(edges_flood_500, \"500 yr\", flood_colors[\"500 yr\"], m_1)\n",
    "add_flooded_roads_layer(edges_DANA_02_11_2024, \"DANA_02_11_2024\", flood_colors[\"DANA_02_11_2024\"], m_1)\n",
    "add_roads_layer(edges, \"All Roads\", \"#000000\", m_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.LayerControl(collapsed=False).add_to(m_1)\n",
    "m_1.save(\"processed_files/m_1.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANA flood depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_2 = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m_2.fit_bounds(map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = DANA_flood_depth[\"depth_val\"].min()\n",
    "max_depth = DANA_flood_depth[\"depth_val\"].max()\n",
    "depth_colormap = linear.YlGnBu_09.scale(min_depth, max_depth)\n",
    "depth_colormap.caption = 'Flood Depth (m)'\n",
    "\n",
    "folium.GeoJson(\n",
    "    DANA_flood_depth,\n",
    "    name=\"DANA flood depth\",\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': depth_colormap(feature['properties']['depth_val']),\n",
    "        'color': 'black',\n",
    "        'weight': 0.5,\n",
    "        'fillOpacity': 0.7\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"depth_val\"], aliases=[\"Depth (m):\"])\n",
    ").add_to(m_2)\n",
    "\n",
    "depth_colormap.add_to(m_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.LayerControl(collapsed=False).add_to(m_2)\n",
    "m_2.save(\"processed_files/m_3.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANA Flooded Area Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_colors = {\n",
    "    \"DANA_02_11_2024\": \"#56B4E9\",   # Sky Blue\n",
    "    \"DANA_03_11_2024\": \"#009E73\",  # Bluish Green\n",
    "    \"DANA_06_11_2024\": \"#E69F00\",  # Orange\n",
    "    \"DANA_08_11_2024\": \"#CC79A7\"  # Reddish Purple\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_3 = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\", max_bounds=True)\n",
    "m_3.fit_bounds(map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flood zones\n",
    "add_flood_zone_layer(flood_zone_DANA_02_11_2024, \"DANA_02_11_2024\", flood_colors[\"DANA_02_11_2024\"], m_3)\n",
    "add_flood_zone_layer(flood_zone_DANA_03_11_2024, \"DANA_03_11_2024\", flood_colors[\"DANA_03_11_2024\"], m_3)\n",
    "add_flood_zone_layer(flood_zone_DANA_06_11_2024, \"DANA_06_11_2024\", flood_colors[\"DANA_06_11_2024\"], m_3)\n",
    "add_flood_zone_layer(flood_zone_DANA_08_11_2024, \"DANA_08_11_2024\", flood_colors[\"DANA_08_11_2024\"], m_3)\n",
    "    \n",
    "# Add flooded roads (optional)\n",
    "add_flooded_roads_layer(edges_DANA_02_11_2024, \"DANA_02_11_2024\", flood_colors[\"DANA_02_11_2024\"], m_3)\n",
    "add_flooded_roads_layer(edges_DANA_03_11_2024, \"DANA_03_11_2024\", flood_colors[\"DANA_03_11_2024\"], m_3)\n",
    "add_flooded_roads_layer(edges_DANA_06_11_2024, \"DANA_06_11_2024\", flood_colors[\"DANA_06_11_2024\"], m_3)\n",
    "add_flooded_roads_layer(edges_DANA_08_11_2024, \"DANA_08_11_2024\", flood_colors[\"DANA_08_11_2024\"], m_3)\n",
    "add_roads_layer(edges, \"All Roads\", \"#000000\", m_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.LayerControl(collapsed=False).add_to(m_3)\n",
    "m_3.save(\"processed_files/m_3.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (oxenv)",
   "language": "python",
   "name": "oxenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
